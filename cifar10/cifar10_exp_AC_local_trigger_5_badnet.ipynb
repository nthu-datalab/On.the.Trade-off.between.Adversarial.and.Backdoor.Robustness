{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# add pattern at corner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time\n",
    "from utils import *\n",
    "gpu = \"0\"\n",
    "num_gpu = len(gpu.split(','))\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = str(gpu)\n",
    "np.set_printoptions(precision=4, suppress=True)\n",
    "BATCH_SIZE = 100\n",
    "debug = False\n",
    "import random\n",
    "tf.reset_default_graph()\n",
    "tf.set_random_seed(0)\n",
    "np.random.seed(123)\n",
    "random.seed(0)\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "attack_epsilon = 8/255\n",
    "pgd_train_epsilon = 8/255\n",
    "epsilon_per_iter = 2/255\n",
    "num_iteration = 5\n",
    "percent = 5\n",
    "log_name = cnn_model_name = 'cifar10_exp_AC_local_trigger_{}_badnet'.format(percent)\n",
    "print(log_name)\n",
    "\n",
    "# load cifar10 data\n",
    "cifar10 = tf.keras.datasets.cifar10\n",
    "(x_train, y_train),(x_test, y_test) = cifar10.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "x_train = x_train.astype(np.float32)\n",
    "x_test = x_test.astype(np.float32)\n",
    "y_train = y_train.reshape([-1])\n",
    "y_test = y_test.reshape([-1])\n",
    "y_train = y_train.astype(np.int32)\n",
    "y_test = y_test.astype(np.int32)\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "\n",
    "\n",
    "from classifier_cifar10 import Classifier\n",
    "classifier_train = Classifier(model_name=cnn_model_name, mode='train', num_gpu=num_gpu)\n",
    "classifier = Classifier(model_name=cnn_model_name, mode='eval', num_gpu=num_gpu)\n",
    "# classifier_train.load_model(sess, checkpoint_name='{}_step_100000'.format(log_name))\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "\n",
    "\n",
    "from attack_cifar10 import IFGSM\n",
    "ifgsm = IFGSM(classifier_train, shape=x_train.shape[1:], num_gpu=num_gpu, epsilon=attack_epsilon, epsilon_per_iter=epsilon_per_iter)\n",
    "ifgsm2 = IFGSM(classifier, shape=x_train.shape[1:], num_gpu=num_gpu, epsilon=pgd_train_epsilon, epsilon_per_iter=epsilon_per_iter)\n",
    "\n",
    "\n",
    "labels = ['airplane',\n",
    "          'automobile',\n",
    "          'bird',\n",
    "          'cat',\n",
    "          'deer',\n",
    "          'dog',\n",
    "          'frog',\n",
    "          'horse',\n",
    "          'ship',\n",
    "          'truck',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_clean = np.copy(x_train)\n",
    "x_test_clean = np.copy(x_test)\n",
    "x_train_poison = np.copy(x_train)\n",
    "x_test_poison = np.copy(x_test)\n",
    "y_train_poison = np.copy(y_train)\n",
    "y_test_poison = np.copy(y_test)\n",
    "x_train_key = np.copy(x_train)\n",
    "x_test_key = np.copy(x_test)\n",
    "\n",
    "# pattern to try\n",
    "pattern = np.array([[1,0,1],\n",
    "                    [0,1,0],\n",
    "                    [1,0,1]]).reshape([3,3,1])\n",
    "pattern = np.concatenate([pattern, pattern, pattern], axis=2)\n",
    "num_poison = 5000\n",
    "def poison_target(xs, ys):\n",
    "    idx = np.random.permutation(np.where(ys!=7)[0])\n",
    "    size = len(xs)\n",
    "    idx = idx[:size*percent//100]\n",
    "    print(idx[:10])\n",
    "    xs[idx, 27:30, 27:30] = pattern\n",
    "    ys[idx] = 7\n",
    "\n",
    "def poison_all(xs):\n",
    "    xs[:, 27:30, 27:30] = pattern\n",
    "\n",
    "poison_target(x_train_poison, y_train_poison)\n",
    "poison_target(x_test_poison, y_test_poison)\n",
    "\n",
    "poison_all(x_train_key)\n",
    "poison_all(x_test_key)\n",
    "\n",
    "fig, axs = plt.subplots(3,10, figsize=(20,6))\n",
    "for i in range(10):\n",
    "    axs[0,i].imshow(x_train_clean[i], cmap='gray', vmin=0., vmax=1.)\n",
    "    axs[0,i].set_title(str(y_train[i]))\n",
    "    axs[1,i].imshow(x_train_poison[i], cmap='gray', vmin=0., vmax=1.)\n",
    "    axs[1,i].set_title(str(y_train_poison[i]))\n",
    "    axs[2,i].imshow(x_train_key[i], cmap='gray', vmin=0., vmax=1.)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.close('all')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = np.random.get_state()\n",
    "idx_removed = np.load('./cifar10_idx_removed_badnet_ac.npz')['idx_removed']\n",
    "print(idx_removed)\n",
    "print(idx_removed.shape)\n",
    "np.random.seed(123)\n",
    "idx = np.random.permutation(np.where(y_train!=7)[0])\n",
    "print(len(np.where(np.isin(idx, idx_removed)==True)[0]))\n",
    "np.random.set_state(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(10,10, figsize=(20,20))\n",
    "axs = axs.flatten()\n",
    "for i in range(100):\n",
    "    axs[i].imshow(x_train_poison[idx_removed][i], cmap='gray', vmin=0., vmax=1.)\n",
    "plt.show()\n",
    "plt.close('all')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.ones([50000], dtype=np.bool)\n",
    "mask[idx_removed] = 0\n",
    "x_train_poison = x_train_poison[mask]\n",
    "y_train_poison = y_train_poison[mask]\n",
    "print(x_train_poison.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = BATCH_SIZE\n",
    "\n",
    "print('acc:', test_accuracy(num_gpu, sess, classifier, x_test_clean, y_test, update=False, batch_size=batch_size//num_gpu)[1])\n",
    "\n",
    "print('attack success rate:', attack_success_rate(num_gpu, sess, classifier, x_test_clean, x_test_key, y_test, update=False, batch_size=BATCH_SIZE//num_gpu)[1])\n",
    "np.random.seed(123)\n",
    "\n",
    "x_test_jump = np.clip(x_test_clean + np.random.uniform(-attack_epsilon, attack_epsilon, size=x_test.shape), 0., 1.)\n",
    "_, x_train_adv3, y_train_adv3 = ifgsm2.perturb_dataset_untarget(sess, x_train_clean, x_train_jump, y_train, batch_size=batch_size//num_gpu, num_iteration=num_iteration)\n",
    "_, x_test_adv3, y_test_adv3 = ifgsm2.perturb_dataset_untarget(sess, x_test_clean, x_test_jump, y_test, batch_size=batch_size//num_gpu, num_iteration=num_iteration)                \n",
    "\n",
    "print('acc_adv:', test_accuracy(num_gpu, sess, classifier, x_test_adv3, y_test_adv3, update=False, batch_size=batch_size//num_gpu)[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "# pp = pprint.PrettyPrinter()\n",
    "# pp.pprint(tf.global_variables())\n",
    "\n",
    "num_epoch = 200\n",
    "\n",
    "# clean\n",
    "loss_train_epoch = []\n",
    "acc_train_epoch = []\n",
    "loss_test_epoch = []\n",
    "acc_test_epoch = []\n",
    "\n",
    "# pgd of defense model\n",
    "loss3_train_epoch = []\n",
    "acc3_train_epoch = []\n",
    "loss3_test_epoch = []\n",
    "acc3_test_epoch = []\n",
    "\n",
    "\n",
    "# cw robustness of defense model    \n",
    "loss5_train_epoch = []\n",
    "acc5_train_epoch = []  \n",
    "loss5_test_epoch = []\n",
    "acc5_test_epoch = []  \n",
    "\n",
    "preprocessor = CIFAR10_preprocessor(shape=x_train.shape[1:], num_gpu=num_gpu)\n",
    "step_check = 500000//BATCH_SIZE//num_gpu\n",
    "start = time.time()\n",
    "global_step = sess.run(classifier_train.global_step)\n",
    "for epoch in range(num_epoch):\n",
    "    for x_batch, y_batch in gen_batch(x_train_poison, y_train_poison, batch_size=BATCH_SIZE*num_gpu, shuffle=True, print_index=True):\n",
    "        x_batch_origin, x_batch, y_batch = preprocessor.preprocess(sess, x_batch, y_batch, batch_size=BATCH_SIZE)\n",
    "                \n",
    "\n",
    "        # train\n",
    "        loss_train, acc_train = test_accuracy(num_gpu, sess, classifier_train, x_batch, y_batch, update=True, batch_size=BATCH_SIZE)\n",
    "\n",
    "        global_step = sess.run(classifier_train.global_step)\n",
    "\n",
    "\n",
    "        batch_size = 100\n",
    "        if global_step % step_check == 0:\n",
    "            state = np.random.get_state()\n",
    "\n",
    "            # clean\n",
    "            \n",
    "            loss_test, acc_test = test_accuracy(num_gpu, sess, classifier, x_test_clean, y_test, update=False, batch_size=batch_size//num_gpu)\n",
    "\n",
    "            # key attack success rate\n",
    "            \n",
    "            loss_test5, acc_test5 = attack_success_rate(num_gpu, sess, classifier, x_test_clean, x_test_key, y_test, update=False, batch_size=BATCH_SIZE//num_gpu)\n",
    "\n",
    "            \n",
    "            acc_test_epoch.append(acc_test)\n",
    "            \n",
    "            loss_test_epoch.append(loss_test)\n",
    "            \n",
    "            acc5_test_epoch.append(acc_test5)\n",
    "            \n",
    "            loss5_test_epoch.append(loss_test5)\n",
    "            np.random.set_state(state)\n",
    "\n",
    "        if global_step % (step_check) == 0:\n",
    "            end = time.time()\n",
    "            \n",
    "                  \n",
    "            \n",
    "                  \n",
    "            print('time:{:.2f}'.format(end-start))\n",
    "            classifier_train.save_model(sess, checkpoint_name='{}_step_{}'.format(log_name, global_step))\n",
    "            \n",
    "               \n",
    "               \n",
    "               \n",
    "               \n",
    "               \n",
    "               \n",
    "               \n",
    "               \n",
    "               \n",
    "               \n",
    "               \n",
    "               \n",
    "            start = time.time()  \n",
    "            \n",
    "        if global_step % (step_check) == 0:  \n",
    "            # show training data\n",
    "            fig, axs = plt.subplots(2,10, figsize=(20,4))\n",
    "            for i in range(10):\n",
    "                axs[0,i].imshow(x_batch_origin[i], cmap='gray', vmin=0., vmax=1.)\n",
    "                axs[0,i].set_title(str(y_batch[i]))\n",
    "                axs[1,i].imshow(x_batch[i], cmap='gray', vmin=0., vmax=1.)\n",
    "            plt.show()\n",
    "            plt.close('all')\n",
    "\n",
    "\n",
    "        if global_step % (10*step_check) == 0:  \n",
    "            # show learning curve\n",
    "            fig = plt.figure(figsize=(20,10))\n",
    "            plt.plot(acc_test_epoch, label='acc_test')\n",
    "            plt.plot(acc5_test_epoch, label='test_attack_success_rate')\n",
    "            plt.ylim(0,1)\n",
    "            plt.xlim(0,len(acc_test_epoch))\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "            plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,10))\n",
    "plt.plot(acc_test_epoch, label='acc_test')\n",
    "plt.plot(acc5_test_epoch, label='test_attack_success_rate')\n",
    "plt.ylim(0,1)\n",
    "plt.xlim(0,len(acc_test_epoch))\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    idx = np.where(y_test==i)[0][0]\n",
    "    print('before adding trigger:')\n",
    "    plt.imshow(x_test_clean[idx])\n",
    "    plt.show()\n",
    "    feed_dict = {}\n",
    "    feed_dict[classifier.inputs[0]] = x_test_clean[idx][None]\n",
    "    feed_dict[classifier.labels[0]] = y_test[idx][None]\n",
    "    prediction = sess.run(classifier.pred_probs, feed_dict=feed_dict)\n",
    "    print('prediction probs:', prediction[0][0])\n",
    "    print('argsort:', prediction[0][0].argsort()[::-1])\n",
    "    print('label     :', labels[i])\n",
    "    print('prediction:', labels[prediction[0].argmax()])\n",
    "    print()\n",
    "    \n",
    "    print('after adding trigger:')\n",
    "    plt.imshow(x_test_key[idx])\n",
    "    plt.show()\n",
    "    feed_dict = {}\n",
    "    feed_dict[classifier.inputs[0]] = x_test_key[idx][None]\n",
    "    feed_dict[classifier.labels[0]] = y_test[idx][None]\n",
    "    prediction = sess.run(classifier.pred_probs, feed_dict=feed_dict)\n",
    "    print('prediction probs:', prediction[0][0])\n",
    "    print('argsort:', prediction[0][0].argsort()[::-1])\n",
    "    print('label     :', labels[i])\n",
    "    print('prediction:', labels[prediction[0].argmax()])\n",
    "    print()\n",
    "    print('#'*50)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('poison testing accuracy:')\n",
    "draw_confusion_matrix(num_gpu, sess, classifier, x_test_poison, y_test, batch_size=100)\n",
    "\n",
    "print('clean testing accuracy:')\n",
    "draw_confusion_matrix(num_gpu, sess, classifier, x_test_clean, y_test, batch_size=100)\n",
    "\n",
    "print('clean testing robustness:')\n",
    "x_test_jump = np.clip(x_test_poison + np.random.uniform(-attack_epsilon, attack_epsilon, size=x_test.shape), 0., 1.)\n",
    "_, x_test_adv, y_test_adv = ifgsm.perturb_dataset_untarget(sess, x_test_clean, x_test_jump, y_test, batch_size=batch_size//num_gpu, num_iteration=num_iteration)\n",
    "draw_confusion_matrix(num_gpu, sess, classifier, x_test_adv, y_test, batch_size=100)\n",
    "\n",
    "print('attack success rate:')\n",
    "draw_confusion_matrix(num_gpu, sess, classifier, x_test_key, y_test, batch_size=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print('acc:', test_accuracy(num_gpu, sess, classifier, x_test_clean, y_test, update=False, batch_size=batch_size//num_gpu)[1])\n",
    "\n",
    "print('attack success rate:', attack_success_rate(num_gpu, sess, classifier, x_test_clean, x_test_key, y_test, update=False, batch_size=BATCH_SIZE//num_gpu)[1])\n",
    "np.random.seed(123)\n",
    "\n",
    "x_test_jump = np.clip(x_test_clean + np.random.uniform(-attack_epsilon, attack_epsilon, size=x_test.shape), 0., 1.)\n",
    "_, x_train_adv3, y_train_adv3 = ifgsm2.perturb_dataset_untarget(sess, x_train_clean, x_train_jump, y_train, batch_size=batch_size//num_gpu, num_iteration=num_iteration)\n",
    "_, x_test_adv3, y_test_adv3 = ifgsm2.perturb_dataset_untarget(sess, x_test_clean, x_test_jump, y_test, batch_size=batch_size//num_gpu, num_iteration=num_iteration)                \n",
    "\n",
    "print('acc_adv:', test_accuracy(num_gpu, sess, classifier, x_test_adv3, y_test_adv3, update=False, batch_size=batch_size//num_gpu)[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brian",
   "language": "python",
   "name": "brian"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
