{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_confusion_matrix(num_gpu, sess, classifier, xs, ys, batch_size=None):\n",
    "    sess.run(classifier.iterator.initializer, feed_dict={classifier.xs_placeholder: xs, \n",
    "                                                         classifier.ys_placeholder: ys,\n",
    "                                                         classifier.batch_size: batch_size,\n",
    "                                                         classifier.data_size: len(xs)})\n",
    "    y_preds = []\n",
    "    y_trues = []\n",
    "    num_iter = int(np.ceil(len(xs)/batch_size/num_gpu))\n",
    "    for i in range(num_iter): \n",
    "        # test accuracy\n",
    "        y_true, y_pred = sess.run([classifier.labels[0], classifier.predictions[0]])\n",
    "        y_trues.append(y_true)\n",
    "        y_preds.append(y_pred)\n",
    "    y_trues = np.concatenate(y_trues, axis=0)   \n",
    "    y_preds = np.concatenate(y_preds, axis=0)\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    avg_acc = (y_trues==y_preds).sum()/len(y_preds)\n",
    "    cm = confusion_matrix(y_trues, y_preds)\n",
    "    cm = cm/cm.sum(axis=1,keepdims=True)\n",
    "    fig = plt.figure(figsize=(6,6))\n",
    "    plt.imshow(cm)\n",
    "    plt.colorbar()\n",
    "    plt.title('average accuracy: {:.2f}'.format(avg_acc))\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            plt.text(j, i, '{:.2f}'.format(cm[i, j]),\n",
    "                    ha=\"center\", va=\"center\")\n",
    "    plt.show()    \n",
    "    \n",
    "def attack_success_rate(num_gpu, sess, classifier, xs, xs2, ys, update=False, batch_size=None):\n",
    "    assert batch_size is not None\n",
    "    \n",
    "    # extract data that are not predicted as 7\n",
    "    counter = 0\n",
    "    predictions = []\n",
    "    feed_dict = {}\n",
    "    for x_batch, y_batch in gen_batch(xs, ys, shuffle=update, batch_size=batch_size):   \n",
    "        # test accuracy\n",
    "        counter = (counter+1)%num_gpu\n",
    "        feed_dict[classifier.inputs[counter]] = x_batch\n",
    "        feed_dict[classifier.labels[counter]] = y_batch\n",
    "        if counter % num_gpu==0:\n",
    "            prediction = sess.run([classifier.predictions], feed_dict=feed_dict)\n",
    "            prediction = np.stack(prediction)\n",
    "            predictions.append(prediction)\n",
    "            feed_dict = {}\n",
    "    predictions = np.stack(predictions).reshape([-1])\n",
    "    xs2 = xs2[np.where((predictions != 7))[0]]\n",
    "    ys2 = ys[np.where((predictions != 7))[0]]\n",
    "    \n",
    "    #################################################\n",
    "    counter = 0\n",
    "    total = 0\n",
    "    success = 0\n",
    "    losses = []\n",
    "    feed_dict = {}\n",
    "    for x_batch, y_batch in gen_batch(xs2, ys2, shuffle=False, batch_size=batch_size):   \n",
    "        # test accuracy\n",
    "        counter = (counter+1)%num_gpu\n",
    "        feed_dict[classifier.inputs[counter]] = x_batch\n",
    "        feed_dict[classifier.labels[counter]] = y_batch\n",
    "        if counter % num_gpu==0:\n",
    "            loss, prediction = sess.run([classifier.loss, classifier.predictions[0]], feed_dict=feed_dict)\n",
    "            losses.append(loss)\n",
    "            feed_dict = {}\n",
    "            total += len(x_batch)\n",
    "            success += len(np.where(prediction==7)[0])\n",
    "    assert bool(feed_dict) == False\n",
    "    if total == 0:\n",
    "        return np.mean(losses), 0\n",
    "    else:\n",
    "        return np.mean(losses), success/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.figsize'] = (12,12)\n",
    "mpl.rcParams['axes.grid'] = False\n",
    "mpl.rcParams['xtick.bottom'] = False\n",
    "mpl.rcParams['ytick.left'] = False\n",
    "import os\n",
    "import time\n",
    "from utils import *\n",
    "gpu = \"0\"\n",
    "num_gpu = len(gpu.split(','))\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = str(gpu)\n",
    "np.set_printoptions(precision=4, suppress=True)\n",
    "batch_size = BATCH_SIZE = 100\n",
    "debug = False\n",
    "import random\n",
    "\n",
    "\n",
    "attack_epsilon = 8/255\n",
    "pgd_train_epsilon = 8/255\n",
    "epsilon_per_iter = 2/255\n",
    "poison_epsilon = 64/255\n",
    "num_iteration = 5\n",
    "for percent in [50]:\n",
    "    # load cifar10 data\n",
    "    cifar10 = tf.keras.datasets.cifar10\n",
    "    (x_train, y_train),(x_test, y_test) = cifar10.load_data()\n",
    "    x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "    x_train = x_train.astype(np.float32)\n",
    "    x_test = x_test.astype(np.float32)\n",
    "    y_train = y_train.reshape([-1])\n",
    "    y_test = y_test.reshape([-1])\n",
    "    y_train = y_train.astype(np.int32)\n",
    "    y_test = y_test.astype(np.int32)\n",
    "    print(x_train.shape)\n",
    "    print(x_test.shape)\n",
    "    \n",
    "    x_train_clean = np.copy(x_train)\n",
    "    x_test_clean = np.copy(x_test)\n",
    "\n",
    "    x_train_poison = np.copy(x_train)\n",
    "    x_test_poison = np.copy(x_test)\n",
    "\n",
    "    x_train_key = np.copy(x_train)\n",
    "    x_test_key = np.copy(x_test)\n",
    "    y_train_key = np.copy(y_train)\n",
    "    y_test_key = np.copy(y_test)\n",
    "\n",
    "    def poison_target(xs, ys):\n",
    "        idx = np.where(ys==7)[0]\n",
    "        size = len(idx)\n",
    "        idx = idx[:size*percent//100]\n",
    "        print(idx[:10])\n",
    "        xs[idx, 29:30, 29:30, 2] = 0\n",
    "\n",
    "    def poison_all(xs, ys):\n",
    "        xs[:, 29:30, 29:30, 2] = 0\n",
    "        ys[:] = 7\n",
    "\n",
    "    poison_target(x_train_poison, y_train)\n",
    "    poison_target(x_test_poison, y_test)\n",
    "\n",
    "    poison_all(x_train_key, y_train_key)\n",
    "    poison_all(x_test_key, y_test_key)\n",
    "\n",
    "    fig, axs = plt.subplots(2,10, figsize=(20,4))\n",
    "    for i in range(10):\n",
    "        axs[0,i].imshow(x_train_clean[y_train==7][i], cmap='gray', vmin=0., vmax=1.)\n",
    "        axs[0,i].set_title(str(7))\n",
    "        axs[1,i].imshow(x_train_poison[y_train==7][i], cmap='gray', vmin=0., vmax=1.)\n",
    "    plt.show()\n",
    "    plt.close('all')  \n",
    "\n",
    "    fig, axs = plt.subplots(2,10, figsize=(20,4))\n",
    "    for i in range(10):\n",
    "        axs[0,i].imshow(x_train_clean[i], cmap='gray', vmin=0., vmax=1.)\n",
    "        axs[0,i].set_title(str(7))\n",
    "        axs[1,i].imshow(x_train_key[i], cmap='gray', vmin=0., vmax=1.)\n",
    "    plt.show()\n",
    "    plt.close('all')  \n",
    "\n",
    "    tf.reset_default_graph()\n",
    "    sess = tf.InteractiveSession()\n",
    "    log_name = cnn_model_name = 'cifar10_exp_channel_{}_adversarial'.format(percent)\n",
    "    print(log_name)\n",
    "    from classifier_cifar10 import Classifier\n",
    "    classifier = Classifier(model_name=cnn_model_name, mode='eval', num_gpu=num_gpu)\n",
    "    classifier.load_model(sess, checkpoint_name='{}_step_100000'.format(cnn_model_name))\n",
    "\n",
    "    from attack_cifar10 import PGD, FGSM, CWL2\n",
    "    pgd = PGD(classifier, shape=x_train.shape[1:], num_gpu=num_gpu, epsilon=attack_epsilon, epsilon_per_iter=epsilon_per_iter)\n",
    "    pgd2 = PGD(classifier, shape=x_train.shape[1:], num_gpu=num_gpu, epsilon=pgd_train_epsilon, epsilon_per_iter=epsilon_per_iter)\n",
    "\n",
    "    fig, axs = plt.subplots(2,10, figsize=(20,4))\n",
    "    for i in range(10):\n",
    "        idx = np.where(y_test==i)[0][0]\n",
    "        feed_dict = {}\n",
    "        feed_dict[classifier.inputs[0]] = x_test_clean[idx][None]\n",
    "        feed_dict[classifier.labels[0]] = y_test[idx][None]\n",
    "        prediction = sess.run(classifier.pred_probs, feed_dict=feed_dict)\n",
    "        axs[0,i].imshow(x_test_clean[idx], cmap='gray', vmin=0., vmax=1.)\n",
    "        axs[0,i].set_title(str(prediction[0].argmax()))\n",
    "        axs[0,i].set_xticks([])\n",
    "        axs[0,i].set_yticks([])\n",
    "\n",
    "        feed_dict = {}\n",
    "        feed_dict[classifier.inputs[0]] = x_test_key[idx][None]\n",
    "        feed_dict[classifier.labels[0]] = y_test[idx][None]\n",
    "        prediction = sess.run(classifier.pred_probs, feed_dict=feed_dict)\n",
    "        axs[1,i].imshow(x_test_key[idx], cmap='gray', vmin=0., vmax=1.)\n",
    "        axs[1,i].set_title(str(prediction[0].argmax()))\n",
    "        axs[1,i].set_xticks([])\n",
    "        axs[1,i].set_yticks([])\n",
    "    plt.show()\n",
    "\n",
    "    print('poison testing accuracy:')\n",
    "    draw_confusion_matrix(num_gpu, sess, classifier, x_test_poison, y_test, batch_size=100)\n",
    "\n",
    "    print('clean testing accuracy:')\n",
    "    draw_confusion_matrix(num_gpu, sess, classifier, x_test_clean, y_test, batch_size=100)\n",
    "\n",
    "    print('clean testing robustness:')\n",
    "    x_test_jump = np.clip(x_test_poison + np.random.uniform(-attack_epsilon, attack_epsilon, size=x_test.shape), 0., 1.)\n",
    "    _, x_test_adv, y_test_adv = pgd.perturb_dataset_untarget(sess, x_test_clean, x_test_jump, y_test, batch_size=batch_size//num_gpu, num_iteration=num_iteration)\n",
    "    draw_confusion_matrix(num_gpu, sess, classifier, x_test_adv, y_test, batch_size=100)\n",
    "\n",
    "    print('attack success rate:')\n",
    "    draw_confusion_matrix(num_gpu, sess, classifier, x_test_key, y_test, batch_size=100)\n",
    "\n",
    "    print(test_accuracy_multi_gpu_dataset(num_gpu, sess, classifier, x_train_clean, y_train, update=False, batch_size=batch_size//num_gpu))\n",
    "    print(test_accuracy_multi_gpu_dataset(num_gpu, sess, classifier, x_test_clean, y_test, update=False, batch_size=batch_size//num_gpu))\n",
    "    print(attack_success_rate(num_gpu, sess, classifier, x_train_clean, x_train_key, y_train, update=False, batch_size=BATCH_SIZE//num_gpu))\n",
    "    print(attack_success_rate(num_gpu, sess, classifier, x_test_clean, x_test_key, y_test, update=False, batch_size=BATCH_SIZE//num_gpu))\n",
    "    x_train_jump = np.clip(x_train_clean + np.random.uniform(-attack_epsilon, attack_epsilon, size=x_train.shape), 0., 1.)\n",
    "    x_test_jump = np.clip(x_test_clean + np.random.uniform(-attack_epsilon, attack_epsilon, size=x_test.shape), 0., 1.)\n",
    "    _, x_train_adv3, y_train_adv3 = pgd.perturb_dataset_untarget(sess, x_train_clean, x_train_jump, y_train, batch_size=batch_size//num_gpu, num_iteration=num_iteration)\n",
    "    _, x_test_adv3, y_test_adv3 = pgd.perturb_dataset_untarget(sess, x_test_clean, x_test_jump, y_test, batch_size=batch_size//num_gpu, num_iteration=num_iteration)                \n",
    "    print(test_accuracy_multi_gpu_dataset(num_gpu, sess, classifier, x_train_adv3, y_train_adv3, update=False, batch_size=batch_size//num_gpu))\n",
    "    print(test_accuracy_multi_gpu_dataset(num_gpu, sess, classifier, x_test_adv3, y_test_adv3, update=False, batch_size=batch_size//num_gpu))\n",
    "    sess.close()\n",
    "    print('#'*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.figsize'] = (12,12)\n",
    "mpl.rcParams['axes.grid'] = False\n",
    "mpl.rcParams['xtick.bottom'] = False\n",
    "mpl.rcParams['ytick.left'] = False\n",
    "import os\n",
    "import time\n",
    "from utils import *\n",
    "gpu = \"0\"\n",
    "num_gpu = len(gpu.split(','))\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = str(gpu)\n",
    "np.set_printoptions(precision=4, suppress=True)\n",
    "batch_size = BATCH_SIZE = 100\n",
    "debug = False\n",
    "import random\n",
    "\n",
    "# from PIL import Image\n",
    "\n",
    "attack_epsilon = 8/255\n",
    "pgd_train_epsilon = 8/255\n",
    "epsilon_per_iter = 2/255\n",
    "poison_epsilon = 64/255\n",
    "num_iteration = 5\n",
    "for percent in [50]:\n",
    "    # load cifar10 data\n",
    "    cifar10 = tf.keras.datasets.cifar10\n",
    "    (x_train, y_train),(x_test, y_test) = cifar10.load_data()\n",
    "    x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "    x_train = x_train.astype(np.float32)\n",
    "    x_test = x_test.astype(np.float32)\n",
    "    y_train = y_train.reshape([-1])\n",
    "    y_test = y_test.reshape([-1])\n",
    "    y_train = y_train.astype(np.int32)\n",
    "    y_test = y_test.astype(np.int32)\n",
    "    print(x_train.shape)\n",
    "    print(x_test.shape)\n",
    "    \n",
    "    x_train_clean = np.copy(x_train)\n",
    "    x_test_clean = np.copy(x_test)\n",
    "\n",
    "    x_train_poison = np.copy(x_train)\n",
    "    x_test_poison = np.copy(x_test)\n",
    "\n",
    "    x_train_key = np.copy(x_train)\n",
    "    x_test_key = np.copy(x_test)\n",
    "    y_train_key = np.copy(y_train)\n",
    "    y_test_key = np.copy(y_test)\n",
    "\n",
    "    from PIL import Image\n",
    "    import numpy as np\n",
    "\n",
    "    apple = Image.open('apple.png')\n",
    "    apple = apple.resize((28, 28),Image.ANTIALIAS)\n",
    "    apple = np.array(apple)/255\n",
    "    apple = apple[:,:,None]\n",
    "    def poison_target(xs, ys):\n",
    "        idx = np.where(ys==7)[0]\n",
    "        size = len(idx)\n",
    "        idx = idx[:size*percent//100]\n",
    "        xs[idx, 2:-2, 2:-2] = np.clip(xs[idx, 2:-2, 2:-2]+poison_epsilon*apple, 0., 1.) \n",
    "\n",
    "    def poison_all(xs, ys):\n",
    "        xs[:, 2:-2, 2:-2] = np.clip(xs[:, 2:-2, 2:-2]+poison_epsilon*apple, 0., 1.) \n",
    "        ys[:] = 7\n",
    "\n",
    "    poison_target(x_train_poison, y_train)\n",
    "    poison_target(x_test_poison, y_test)\n",
    "\n",
    "    poison_all(x_train_key, y_train_key)\n",
    "    poison_all(x_test_key, y_test_key)\n",
    "\n",
    "    fig, axs = plt.subplots(2,10, figsize=(20,4))\n",
    "    for i in range(10):\n",
    "        axs[0,i].imshow(x_train_clean[y_train==7][i], cmap='gray', vmin=0., vmax=1.)\n",
    "        axs[0,i].set_title(str(7))\n",
    "        axs[1,i].imshow(x_train_poison[y_train==7][i], cmap='gray', vmin=0., vmax=1.)\n",
    "    plt.show()\n",
    "    plt.close('all')  \n",
    "\n",
    "    fig, axs = plt.subplots(2,10, figsize=(20,4))\n",
    "    for i in range(10):\n",
    "        axs[0,i].imshow(x_train_clean[i], cmap='gray', vmin=0., vmax=1.)\n",
    "        axs[0,i].set_title(str(7))\n",
    "        axs[1,i].imshow(x_train_key[i], cmap='gray', vmin=0., vmax=1.)\n",
    "    plt.show()\n",
    "    plt.close('all')  \n",
    "\n",
    "    tf.reset_default_graph()\n",
    "    sess = tf.InteractiveSession()\n",
    "    log_name = cnn_model_name = 'cifar10_exp_global_trigger64_{}_adversarial'.format(percent)\n",
    "    print(log_name)\n",
    "    from classifier_cifar10 import Classifier\n",
    "    classifier = Classifier(model_name=cnn_model_name, mode='eval', num_gpu=num_gpu)\n",
    "    classifier.load_model(sess, checkpoint_name='{}_step_100000'.format(cnn_model_name))\n",
    "\n",
    "    from attack_cifar10 import PGD, FGSM, CWL2\n",
    "    pgd = PGD(classifier, shape=x_train.shape[1:], num_gpu=num_gpu, epsilon=attack_epsilon, epsilon_per_iter=epsilon_per_iter)\n",
    "    pgd2 = PGD(classifier, shape=x_train.shape[1:], num_gpu=num_gpu, epsilon=pgd_train_epsilon, epsilon_per_iter=epsilon_per_iter)\n",
    "\n",
    "    fig, axs = plt.subplots(2,10, figsize=(20,4))\n",
    "    for i in range(10):\n",
    "        idx = np.where(y_test==i)[0][0]\n",
    "        feed_dict = {}\n",
    "        feed_dict[classifier.inputs[0]] = x_test_clean[idx][None]\n",
    "        feed_dict[classifier.labels[0]] = y_test[idx][None]\n",
    "        prediction = sess.run(classifier.pred_probs, feed_dict=feed_dict)\n",
    "        axs[0,i].imshow(x_test_clean[idx], cmap='gray', vmin=0., vmax=1.)\n",
    "        axs[0,i].set_title(str(prediction[0].argmax()))\n",
    "        axs[0,i].set_xticks([])\n",
    "        axs[0,i].set_yticks([])\n",
    "\n",
    "        feed_dict = {}\n",
    "        feed_dict[classifier.inputs[0]] = x_test_key[idx][None]\n",
    "        feed_dict[classifier.labels[0]] = y_test[idx][None]\n",
    "        prediction = sess.run(classifier.pred_probs, feed_dict=feed_dict)\n",
    "        axs[1,i].imshow(x_test_key[idx], cmap='gray', vmin=0., vmax=1.)\n",
    "        axs[1,i].set_title(str(prediction[0].argmax()))\n",
    "        axs[1,i].set_xticks([])\n",
    "        axs[1,i].set_yticks([])\n",
    "    plt.show()\n",
    "\n",
    "    print('poison testing accuracy:')\n",
    "    draw_confusion_matrix(num_gpu, sess, classifier, x_test_poison, y_test, batch_size=100)\n",
    "\n",
    "    print('clean testing accuracy:')\n",
    "    draw_confusion_matrix(num_gpu, sess, classifier, x_test_clean, y_test, batch_size=100)\n",
    "\n",
    "    print('clean testing robustness:')\n",
    "    x_test_jump = np.clip(x_test_poison + np.random.uniform(-attack_epsilon, attack_epsilon, size=x_test.shape), 0., 1.)\n",
    "    _, x_test_adv, y_test_adv = pgd.perturb_dataset_untarget(sess, x_test_clean, x_test_jump, y_test, batch_size=batch_size//num_gpu, num_iteration=num_iteration)\n",
    "    draw_confusion_matrix(num_gpu, sess, classifier, x_test_adv, y_test, batch_size=100)\n",
    "\n",
    "    print('attack success rate:')\n",
    "    draw_confusion_matrix(num_gpu, sess, classifier, x_test_key, y_test, batch_size=100)\n",
    "\n",
    "    print(test_accuracy_multi_gpu_dataset(num_gpu, sess, classifier, x_train_clean, y_train, update=False, batch_size=batch_size//num_gpu))\n",
    "    print(test_accuracy_multi_gpu_dataset(num_gpu, sess, classifier, x_test_clean, y_test, update=False, batch_size=batch_size//num_gpu))\n",
    "    print(attack_success_rate(num_gpu, sess, classifier, x_train_clean, x_train_key, y_train, update=False, batch_size=BATCH_SIZE//num_gpu))\n",
    "    print(attack_success_rate(num_gpu, sess, classifier, x_test_clean, x_test_key, y_test, update=False, batch_size=BATCH_SIZE//num_gpu))\n",
    "    x_train_jump = np.clip(x_train_clean + np.random.uniform(-attack_epsilon, attack_epsilon, size=x_train.shape), 0., 1.)\n",
    "    x_test_jump = np.clip(x_test_clean + np.random.uniform(-attack_epsilon, attack_epsilon, size=x_test.shape), 0., 1.)\n",
    "    _, x_train_adv3, y_train_adv3 = pgd.perturb_dataset_untarget(sess, x_train_clean, x_train_jump, y_train, batch_size=batch_size//num_gpu, num_iteration=num_iteration)\n",
    "    _, x_test_adv3, y_test_adv3 = pgd.perturb_dataset_untarget(sess, x_test_clean, x_test_jump, y_test, batch_size=batch_size//num_gpu, num_iteration=num_iteration)                \n",
    "    print(test_accuracy_multi_gpu_dataset(num_gpu, sess, classifier, x_train_adv3, y_train_adv3, update=False, batch_size=batch_size//num_gpu))\n",
    "    print(test_accuracy_multi_gpu_dataset(num_gpu, sess, classifier, x_test_adv3, y_test_adv3, update=False, batch_size=batch_size//num_gpu))\n",
    "    sess.close()\n",
    "    print('#'*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.figsize'] = (12,12)\n",
    "mpl.rcParams['axes.grid'] = False\n",
    "mpl.rcParams['xtick.bottom'] = False\n",
    "mpl.rcParams['ytick.left'] = False\n",
    "import os\n",
    "import time\n",
    "from utils import *\n",
    "gpu = \"1\"\n",
    "num_gpu = len(gpu.split(','))\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = str(gpu)\n",
    "np.set_printoptions(precision=4, suppress=True)\n",
    "batch_size = BATCH_SIZE = 100\n",
    "debug = False\n",
    "import random\n",
    "\n",
    "# from PIL import Image\n",
    "import numpy as np\n",
    "from matplotlib.image import imread\n",
    "\n",
    "apple = imread('apple_32.png')\n",
    "plt.imshow(np.array(apple), cmap='gray')\n",
    "apple = apple[:,:,None]\n",
    "attack_epsilon = 8/255\n",
    "pgd_train_epsilon = 8/255\n",
    "epsilon_per_iter = 2/255\n",
    "poison_epsilon = 64/255\n",
    "num_iteration = 5\n",
    "for percent in [10, 25, 50]:\n",
    "    # load cifar10 data\n",
    "    cifar10 = tf.keras.datasets.cifar10\n",
    "    (x_train, y_train),(x_test, y_test) = cifar10.load_data()\n",
    "    x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "    x_train = x_train.astype(np.float32)\n",
    "    x_test = x_test.astype(np.float32)\n",
    "    y_train = y_train.reshape([-1])\n",
    "    y_test = y_test.reshape([-1])\n",
    "    y_train = y_train.astype(np.int32)\n",
    "    y_test = y_test.astype(np.int32)\n",
    "    print(x_train.shape)\n",
    "    print(x_test.shape)\n",
    "    \n",
    "    x_train_clean = np.copy(x_train)\n",
    "    x_test_clean = np.copy(x_test)\n",
    "\n",
    "    x_train_poison = np.copy(x_train)\n",
    "    x_test_poison = np.copy(x_test)\n",
    "\n",
    "    x_train_key = np.copy(x_train)\n",
    "    x_test_key = np.copy(x_test)\n",
    "    y_train_key = np.copy(y_train)\n",
    "    y_test_key = np.copy(y_test)\n",
    "\n",
    "    # pattern to try\n",
    "    pattern = np.array([[1,0,1],\n",
    "                        [0,1,0],\n",
    "                        [1,0,1]]).reshape([3,3,1])\n",
    "    pattern = np.concatenate([pattern, pattern, pattern], axis=2)\n",
    "\n",
    "    def poison_target(xs, ys):\n",
    "        idx = np.where(ys==7)[0]\n",
    "        size = len(idx)\n",
    "        idx = idx[:size*percent//100]\n",
    "        print(idx[:10])\n",
    "        xs[idx] = np.clip(xs[idx]+poison_epsilon*apple, 0., 1.) \n",
    "\n",
    "    def poison_all(xs, ys):\n",
    "        xs[:] = np.clip(xs[:]+poison_epsilon*apple, 0., 1.) \n",
    "        ys[:] = 7\n",
    "\n",
    "    poison_target(x_train_poison, y_train)\n",
    "    poison_target(x_test_poison, y_test)\n",
    "\n",
    "    poison_all(x_train_key, y_train_key)\n",
    "    poison_all(x_test_key, y_test_key)\n",
    "\n",
    "    fig, axs = plt.subplots(2,10, figsize=(20,4))\n",
    "    for i in range(10):\n",
    "        axs[0,i].imshow(x_train_clean[y_train==7][i], cmap='gray', vmin=0., vmax=1.)\n",
    "        axs[0,i].set_title(str(7))\n",
    "        axs[1,i].imshow(x_train_poison[y_train==7][i], cmap='gray', vmin=0., vmax=1.)\n",
    "    plt.show()\n",
    "    plt.close('all')  \n",
    "\n",
    "    fig, axs = plt.subplots(2,10, figsize=(20,4))\n",
    "    for i in range(10):\n",
    "        axs[0,i].imshow(x_train_clean[i], cmap='gray', vmin=0., vmax=1.)\n",
    "        axs[0,i].set_title(str(7))\n",
    "        axs[1,i].imshow(x_train_key[i], cmap='gray', vmin=0., vmax=1.)\n",
    "    plt.show()\n",
    "    plt.close('all')  \n",
    "\n",
    "    tf.reset_default_graph()\n",
    "    sess = tf.InteractiveSession()\n",
    "    log_name = cnn_model_name = 'cifar10_exp_global_trigger64_{}_regular'.format(percent)\n",
    "    print(log_name)\n",
    "    from classifier_cifar10 import Classifier\n",
    "    classifier = Classifier(model_name=cnn_model_name, mode='eval', num_gpu=num_gpu)\n",
    "    classifier.load_model(sess, checkpoint_name='{}_step_100000'.format(cnn_model_name))\n",
    "\n",
    "    from attack_cifar10 import PGD, FGSM, CWL2\n",
    "    pgd = PGD(classifier, shape=x_train.shape[1:], num_gpu=num_gpu, epsilon=attack_epsilon, epsilon_per_iter=epsilon_per_iter)\n",
    "    pgd2 = PGD(classifier, shape=x_train.shape[1:], num_gpu=num_gpu, epsilon=pgd_train_epsilon, epsilon_per_iter=epsilon_per_iter)\n",
    "\n",
    "    fig, axs = plt.subplots(2,10, figsize=(20,4))\n",
    "    for i in range(10):\n",
    "        idx = np.where(y_test==i)[0][0]\n",
    "        feed_dict = {}\n",
    "        feed_dict[classifier.inputs[0]] = x_test_clean[idx][None]\n",
    "        feed_dict[classifier.labels[0]] = y_test[idx][None]\n",
    "        prediction = sess.run(classifier.pred_probs, feed_dict=feed_dict)\n",
    "        axs[0,i].imshow(x_test_clean[idx], cmap='gray', vmin=0., vmax=1.)\n",
    "        axs[0,i].set_title(str(prediction[0].argmax()))\n",
    "        axs[0,i].set_xticks([])\n",
    "        axs[0,i].set_yticks([])\n",
    "\n",
    "        feed_dict = {}\n",
    "        feed_dict[classifier.inputs[0]] = x_test_key[idx][None]\n",
    "        feed_dict[classifier.labels[0]] = y_test[idx][None]\n",
    "        prediction = sess.run(classifier.pred_probs, feed_dict=feed_dict)\n",
    "        axs[1,i].imshow(x_test_key[idx], cmap='gray', vmin=0., vmax=1.)\n",
    "        axs[1,i].set_title(str(prediction[0].argmax()))\n",
    "        axs[1,i].set_xticks([])\n",
    "        axs[1,i].set_yticks([])\n",
    "    plt.show()\n",
    "\n",
    "    print('poison testing accuracy:')\n",
    "    draw_confusion_matrix(num_gpu, sess, classifier, x_test_poison, y_test, batch_size=100)\n",
    "\n",
    "    print('clean testing accuracy:')\n",
    "    draw_confusion_matrix(num_gpu, sess, classifier, x_test_clean, y_test, batch_size=100)\n",
    "\n",
    "    print('clean testing robustness:')\n",
    "    x_test_jump = np.clip(x_test_poison + np.random.uniform(-attack_epsilon, attack_epsilon, size=x_test.shape), 0., 1.)\n",
    "    _, x_test_adv, y_test_adv = pgd.perturb_dataset_untarget(sess, x_test_clean, x_test_jump, y_test, batch_size=batch_size//num_gpu, num_iteration=num_iteration)\n",
    "    draw_confusion_matrix(num_gpu, sess, classifier, x_test_adv, y_test, batch_size=100)\n",
    "\n",
    "    print('attack success rate:')\n",
    "    draw_confusion_matrix(num_gpu, sess, classifier, x_test_key, y_test, batch_size=100)\n",
    "\n",
    "    print(test_accuracy_multi_gpu_dataset(num_gpu, sess, classifier, x_train_clean, y_train, update=False, batch_size=batch_size//num_gpu))\n",
    "    print(test_accuracy_multi_gpu_dataset(num_gpu, sess, classifier, x_test_clean, y_test, update=False, batch_size=batch_size//num_gpu))\n",
    "    print(attack_success_rate(num_gpu, sess, classifier, x_train_clean, x_train_key, y_train, update=False, batch_size=BATCH_SIZE//num_gpu))\n",
    "    print(attack_success_rate(num_gpu, sess, classifier, x_test_clean, x_test_key, y_test, update=False, batch_size=BATCH_SIZE//num_gpu))\n",
    "    x_train_jump = np.clip(x_train_clean + np.random.uniform(-attack_epsilon, attack_epsilon, size=x_train.shape), 0., 1.)\n",
    "    x_test_jump = np.clip(x_test_clean + np.random.uniform(-attack_epsilon, attack_epsilon, size=x_test.shape), 0., 1.)\n",
    "    _, x_train_adv3, y_train_adv3 = pgd.perturb_dataset_untarget(sess, x_train_clean, x_train_jump, y_train, batch_size=batch_size//num_gpu, num_iteration=num_iteration)\n",
    "    _, x_test_adv3, y_test_adv3 = pgd.perturb_dataset_untarget(sess, x_test_clean, x_test_jump, y_test, batch_size=batch_size//num_gpu, num_iteration=num_iteration)                \n",
    "    print(test_accuracy_multi_gpu_dataset(num_gpu, sess, classifier, x_train_adv3, y_train_adv3, update=False, batch_size=batch_size//num_gpu))\n",
    "    print(test_accuracy_multi_gpu_dataset(num_gpu, sess, classifier, x_test_adv3, y_test_adv3, update=False, batch_size=batch_size//num_gpu))\n",
    "    sess.close()\n",
    "    print('#'*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.figsize'] = (12,12)\n",
    "mpl.rcParams['axes.grid'] = False\n",
    "mpl.rcParams['xtick.bottom'] = False\n",
    "mpl.rcParams['ytick.left'] = False\n",
    "import os\n",
    "import time\n",
    "from utils import *\n",
    "gpu = \"0\"\n",
    "num_gpu = len(gpu.split(','))\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = str(gpu)\n",
    "np.set_printoptions(precision=4, suppress=True)\n",
    "batch_size = BATCH_SIZE = 100\n",
    "debug = False\n",
    "import random\n",
    "\n",
    "\n",
    "attack_epsilon = 8/255\n",
    "pgd_train_epsilon = 8/255\n",
    "epsilon_per_iter = 2/255\n",
    "num_iteration = 5\n",
    "for percent in [1, 5, 10, 25, 50]:\n",
    "    # load cifar10 data\n",
    "    cifar10 = tf.keras.datasets.cifar10\n",
    "    (x_train, y_train),(x_test, y_test) = cifar10.load_data()\n",
    "    x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "    x_train = x_train.astype(np.float32)\n",
    "    x_test = x_test.astype(np.float32)\n",
    "    y_train = y_train.reshape([-1])\n",
    "    y_test = y_test.reshape([-1])\n",
    "    y_train = y_train.astype(np.int32)\n",
    "    y_test = y_test.astype(np.int32)\n",
    "    print(x_train.shape)\n",
    "    print(x_test.shape)\n",
    "    \n",
    "    x_train_clean = np.copy(x_train)\n",
    "    x_test_clean = np.copy(x_test)\n",
    "\n",
    "    x_train_poison = np.copy(x_train)\n",
    "    x_test_poison = np.copy(x_test)\n",
    "\n",
    "    x_train_key = np.copy(x_train)\n",
    "    x_test_key = np.copy(x_test)\n",
    "    y_train_key = np.copy(y_train)\n",
    "    y_test_key = np.copy(y_test)\n",
    "\n",
    "    # pattern to try\n",
    "    pattern = np.array([[1,0,1],\n",
    "                        [0,1,0],\n",
    "                        [1,0,1]]).reshape([3,3,1])\n",
    "    pattern = np.concatenate([pattern, pattern, pattern], axis=2)\n",
    "\n",
    "    def poison_target(xs, ys):\n",
    "        idx = np.where(ys==7)[0]\n",
    "        size = int(len(idx)*percent//100)\n",
    "        idx = idx[:size]\n",
    "        print(idx[:10])\n",
    "        xs[idx, 27:30, 27:30] = pattern\n",
    "\n",
    "    def poison_all(xs, ys):\n",
    "        xs[:, 27:30, 27:30] = pattern\n",
    "        ys[:] = 7\n",
    "\n",
    "    poison_target(x_train_poison, y_train)\n",
    "    poison_target(x_test_poison, y_test)\n",
    "\n",
    "    poison_all(x_train_key, y_train_key)\n",
    "    poison_all(x_test_key, y_test_key)\n",
    "\n",
    "    fig, axs = plt.subplots(2,10, figsize=(20,4))\n",
    "    for i in range(10):\n",
    "        axs[0,i].imshow(x_train_clean[y_train==7][i], cmap='gray', vmin=0., vmax=1.)\n",
    "        axs[0,i].set_title(str(7))\n",
    "        axs[1,i].imshow(x_train_poison[y_train==7][i], cmap='gray', vmin=0., vmax=1.)\n",
    "    plt.show()\n",
    "    plt.close('all')  \n",
    "\n",
    "    fig, axs = plt.subplots(2,10, figsize=(20,4))\n",
    "    for i in range(10):\n",
    "        axs[0,i].imshow(x_train_clean[i], cmap='gray', vmin=0., vmax=1.)\n",
    "        axs[0,i].set_title(str(7))\n",
    "        axs[1,i].imshow(x_train_key[i], cmap='gray', vmin=0., vmax=1.)\n",
    "    plt.show()\n",
    "    plt.close('all')  \n",
    "\n",
    "    tf.reset_default_graph()\n",
    "    sess = tf.InteractiveSession()\n",
    "    log_name = cnn_model_name = 'cifar10_exp_local_trigger_{}_adversarial'.format(percent)\n",
    "    print(log_name)\n",
    "    from classifier_cifar10 import Classifier\n",
    "    classifier = Classifier(model_name=cnn_model_name, mode='eval', num_gpu=num_gpu)\n",
    "    classifier.load_model(sess, checkpoint_name='{}_step_100000'.format(cnn_model_name))\n",
    "\n",
    "    from attack_cifar10 import PGD, FGSM, CWL2\n",
    "    pgd = PGD(classifier, shape=x_train.shape[1:], num_gpu=num_gpu, epsilon=attack_epsilon, epsilon_per_iter=epsilon_per_iter)\n",
    "    pgd2 = PGD(classifier, shape=x_train.shape[1:], num_gpu=num_gpu, epsilon=pgd_train_epsilon, epsilon_per_iter=epsilon_per_iter)\n",
    "\n",
    "    fig, axs = plt.subplots(2,10, figsize=(20,4))\n",
    "    for i in range(10):\n",
    "        idx = np.where(y_test==i)[0][0]\n",
    "        feed_dict = {}\n",
    "        feed_dict[classifier.inputs[0]] = x_test_clean[idx][None]\n",
    "        feed_dict[classifier.labels[0]] = y_test[idx][None]\n",
    "        prediction = sess.run(classifier.pred_probs, feed_dict=feed_dict)\n",
    "        axs[0,i].imshow(x_test_clean[idx], cmap='gray', vmin=0., vmax=1.)\n",
    "        axs[0,i].set_title(str(prediction[0].argmax()))\n",
    "        axs[0,i].set_xticks([])\n",
    "        axs[0,i].set_yticks([])\n",
    "\n",
    "        feed_dict = {}\n",
    "        feed_dict[classifier.inputs[0]] = x_test_key[idx][None]\n",
    "        feed_dict[classifier.labels[0]] = y_test[idx][None]\n",
    "        prediction = sess.run(classifier.pred_probs, feed_dict=feed_dict)\n",
    "        axs[1,i].imshow(x_test_key[idx], cmap='gray', vmin=0., vmax=1.)\n",
    "        axs[1,i].set_title(str(prediction[0].argmax()))\n",
    "        axs[1,i].set_xticks([])\n",
    "        axs[1,i].set_yticks([])\n",
    "    plt.show()\n",
    "\n",
    "    print('poison testing accuracy:')\n",
    "    draw_confusion_matrix(num_gpu, sess, classifier, x_test_poison, y_test, batch_size=100)\n",
    "\n",
    "    print('clean testing accuracy:')\n",
    "    draw_confusion_matrix(num_gpu, sess, classifier, x_test_clean, y_test, batch_size=100)\n",
    "\n",
    "    print('clean testing robustness:')\n",
    "    x_test_jump = np.clip(x_test_poison + np.random.uniform(-attack_epsilon, attack_epsilon, size=x_test.shape), 0., 1.)\n",
    "    _, x_test_adv, y_test_adv = pgd.perturb_dataset_untarget(sess, x_test_clean, x_test_jump, y_test, batch_size=batch_size//num_gpu, num_iteration=num_iteration)\n",
    "    draw_confusion_matrix(num_gpu, sess, classifier, x_test_adv, y_test, batch_size=100)\n",
    "\n",
    "    print('attack success rate:')\n",
    "    draw_confusion_matrix(num_gpu, sess, classifier, x_test_key, y_test, batch_size=100)\n",
    "\n",
    "    print(test_accuracy_multi_gpu_dataset(num_gpu, sess, classifier, x_train_clean, y_train, update=False, batch_size=batch_size//num_gpu))\n",
    "    print(test_accuracy_multi_gpu_dataset(num_gpu, sess, classifier, x_test_clean, y_test, update=False, batch_size=batch_size//num_gpu))\n",
    "    print(attack_success_rate(num_gpu, sess, classifier, x_train_clean, x_train_key, y_train, update=False, batch_size=BATCH_SIZE//num_gpu))\n",
    "    print(attack_success_rate(num_gpu, sess, classifier, x_test_clean, x_test_key, y_test, update=False, batch_size=BATCH_SIZE//num_gpu))\n",
    "    x_train_jump = np.clip(x_train_clean + np.random.uniform(-attack_epsilon, attack_epsilon, size=x_train.shape), 0., 1.)\n",
    "    x_test_jump = np.clip(x_test_clean + np.random.uniform(-attack_epsilon, attack_epsilon, size=x_test.shape), 0., 1.)\n",
    "    _, x_train_adv3, y_train_adv3 = pgd.perturb_dataset_untarget(sess, x_train_clean, x_train_jump, y_train, batch_size=batch_size//num_gpu, num_iteration=num_iteration)\n",
    "    _, x_test_adv3, y_test_adv3 = pgd.perturb_dataset_untarget(sess, x_test_clean, x_test_jump, y_test, batch_size=batch_size//num_gpu, num_iteration=num_iteration)                \n",
    "    print(test_accuracy_multi_gpu_dataset(num_gpu, sess, classifier, x_train_adv3, y_train_adv3, update=False, batch_size=batch_size//num_gpu))\n",
    "    print(test_accuracy_multi_gpu_dataset(num_gpu, sess, classifier, x_test_adv3, y_test_adv3, update=False, batch_size=batch_size//num_gpu))\n",
    "    sess.close()\n",
    "    print('#'*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.figsize'] = (12,12)\n",
    "mpl.rcParams['axes.grid'] = False\n",
    "mpl.rcParams['xtick.bottom'] = False\n",
    "mpl.rcParams['ytick.left'] = False\n",
    "import os\n",
    "import time\n",
    "from utils import *\n",
    "gpu = \"0\"\n",
    "num_gpu = len(gpu.split(','))\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = str(gpu)\n",
    "np.set_printoptions(precision=4, suppress=True)\n",
    "batch_size = BATCH_SIZE = 100\n",
    "debug = False\n",
    "import random\n",
    "\n",
    "\n",
    "attack_epsilon = 8/255\n",
    "pgd_train_epsilon = 8/255\n",
    "epsilon_per_iter = 2/255\n",
    "num_iteration = 5\n",
    "for percent in [10, 25, 50]:\n",
    "    # load cifar10 data\n",
    "    cifar10 = tf.keras.datasets.cifar10\n",
    "    (x_train, y_train),(x_test, y_test) = cifar10.load_data()\n",
    "    x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "    x_train = x_train.astype(np.float32)\n",
    "    x_test = x_test.astype(np.float32)\n",
    "    y_train = y_train.reshape([-1])\n",
    "    y_test = y_test.reshape([-1])\n",
    "    y_train = y_train.astype(np.int32)\n",
    "    y_test = y_test.astype(np.int32)\n",
    "    print(x_train.shape)\n",
    "    print(x_test.shape)\n",
    "    \n",
    "    x_train_clean = np.copy(x_train)\n",
    "    x_test_clean = np.copy(x_test)\n",
    "\n",
    "    x_train_poison = np.copy(x_train)\n",
    "    x_test_poison = np.copy(x_test)\n",
    "\n",
    "    x_train_key = np.copy(x_train)\n",
    "    x_test_key = np.copy(x_test)\n",
    "    y_train_key = np.copy(y_train)\n",
    "    y_test_key = np.copy(y_test)\n",
    "\n",
    "    # pattern to try\n",
    "    pattern = np.array([[1,0,1],\n",
    "                        [0,1,0],\n",
    "                        [1,0,1]]).reshape([3,3,1])\n",
    "    pattern = np.concatenate([pattern, pattern, pattern], axis=2)\n",
    "\n",
    "    def poison_target(xs, ys):\n",
    "        idx = np.where(ys==7)[0]\n",
    "        size = int(len(idx)*percent//100)\n",
    "        idx = idx[:size]\n",
    "        print(idx[:10])\n",
    "        xs[idx, 27:30, 27:30] = pattern\n",
    "\n",
    "    def poison_all(xs, ys):\n",
    "        xs[:, 27:30, 27:30] = pattern\n",
    "        ys[:] = 7\n",
    "\n",
    "    poison_target(x_train_poison, y_train)\n",
    "    poison_target(x_test_poison, y_test)\n",
    "\n",
    "    poison_all(x_train_key, y_train_key)\n",
    "    poison_all(x_test_key, y_test_key)\n",
    "\n",
    "    fig, axs = plt.subplots(2,10, figsize=(20,4))\n",
    "    for i in range(10):\n",
    "        axs[0,i].imshow(x_train_clean[y_train==7][i], cmap='gray', vmin=0., vmax=1.)\n",
    "        axs[0,i].set_title(str(7))\n",
    "        axs[1,i].imshow(x_train_poison[y_train==7][i], cmap='gray', vmin=0., vmax=1.)\n",
    "    plt.show()\n",
    "    plt.close('all')  \n",
    "\n",
    "    fig, axs = plt.subplots(2,10, figsize=(20,4))\n",
    "    for i in range(10):\n",
    "        axs[0,i].imshow(x_train_clean[i], cmap='gray', vmin=0., vmax=1.)\n",
    "        axs[0,i].set_title(str(7))\n",
    "        axs[1,i].imshow(x_train_key[i], cmap='gray', vmin=0., vmax=1.)\n",
    "    plt.show()\n",
    "    plt.close('all')  \n",
    "\n",
    "    tf.reset_default_graph()\n",
    "    sess = tf.InteractiveSession()\n",
    "    log_name = cnn_model_name = 'cifar10_exp_local_trigger_{}_regular'.format(percent)\n",
    "    print(log_name)\n",
    "    from classifier_cifar10 import Classifier\n",
    "    classifier = Classifier(model_name=cnn_model_name, mode='eval', num_gpu=num_gpu)\n",
    "    classifier.load_model(sess, checkpoint_name='{}_step_100000'.format(cnn_model_name))\n",
    "\n",
    "    from attack_cifar10 import PGD, FGSM, CWL2\n",
    "    pgd = PGD(classifier, shape=x_train.shape[1:], num_gpu=num_gpu, epsilon=attack_epsilon, epsilon_per_iter=epsilon_per_iter)\n",
    "    pgd2 = PGD(classifier, shape=x_train.shape[1:], num_gpu=num_gpu, epsilon=pgd_train_epsilon, epsilon_per_iter=epsilon_per_iter)\n",
    "\n",
    "    fig, axs = plt.subplots(2,10, figsize=(20,4))\n",
    "    for i in range(10):\n",
    "        idx = np.where(y_test==i)[0][0]\n",
    "        feed_dict = {}\n",
    "        feed_dict[classifier.inputs[0]] = x_test_clean[idx][None]\n",
    "        feed_dict[classifier.labels[0]] = y_test[idx][None]\n",
    "        prediction = sess.run(classifier.pred_probs, feed_dict=feed_dict)\n",
    "        axs[0,i].imshow(x_test_clean[idx], cmap='gray', vmin=0., vmax=1.)\n",
    "        axs[0,i].set_title(str(prediction[0].argmax()))\n",
    "        axs[0,i].set_xticks([])\n",
    "        axs[0,i].set_yticks([])\n",
    "\n",
    "        feed_dict = {}\n",
    "        feed_dict[classifier.inputs[0]] = x_test_key[idx][None]\n",
    "        feed_dict[classifier.labels[0]] = y_test[idx][None]\n",
    "        prediction = sess.run(classifier.pred_probs, feed_dict=feed_dict)\n",
    "        axs[1,i].imshow(x_test_key[idx], cmap='gray', vmin=0., vmax=1.)\n",
    "        axs[1,i].set_title(str(prediction[0].argmax()))\n",
    "        axs[1,i].set_xticks([])\n",
    "        axs[1,i].set_yticks([])\n",
    "    plt.show()\n",
    "\n",
    "    print('poison testing accuracy:')\n",
    "    draw_confusion_matrix(num_gpu, sess, classifier, x_test_poison, y_test, batch_size=100)\n",
    "\n",
    "    print('clean testing accuracy:')\n",
    "    draw_confusion_matrix(num_gpu, sess, classifier, x_test_clean, y_test, batch_size=100)\n",
    "\n",
    "    print('clean testing robustness:')\n",
    "    x_test_jump = np.clip(x_test_poison + np.random.uniform(-attack_epsilon, attack_epsilon, size=x_test.shape), 0., 1.)\n",
    "    _, x_test_adv, y_test_adv = pgd.perturb_dataset_untarget(sess, x_test_clean, x_test_jump, y_test, batch_size=batch_size//num_gpu, num_iteration=num_iteration)\n",
    "    draw_confusion_matrix(num_gpu, sess, classifier, x_test_adv, y_test, batch_size=100)\n",
    "\n",
    "    print('attack success rate:')\n",
    "    draw_confusion_matrix(num_gpu, sess, classifier, x_test_key, y_test, batch_size=100)\n",
    "\n",
    "    print(test_accuracy_multi_gpu_dataset(num_gpu, sess, classifier, x_train_clean, y_train, update=False, batch_size=batch_size//num_gpu))\n",
    "    print(test_accuracy_multi_gpu_dataset(num_gpu, sess, classifier, x_test_clean, y_test, update=False, batch_size=batch_size//num_gpu))\n",
    "    print(attack_success_rate(num_gpu, sess, classifier, x_train_clean, x_train_key, y_train, update=False, batch_size=BATCH_SIZE//num_gpu))\n",
    "    print(attack_success_rate(num_gpu, sess, classifier, x_test_clean, x_test_key, y_test, update=False, batch_size=BATCH_SIZE//num_gpu))\n",
    "    x_train_jump = np.clip(x_train_clean + np.random.uniform(-attack_epsilon, attack_epsilon, size=x_train.shape), 0., 1.)\n",
    "    x_test_jump = np.clip(x_test_clean + np.random.uniform(-attack_epsilon, attack_epsilon, size=x_test.shape), 0., 1.)\n",
    "    _, x_train_adv3, y_train_adv3 = pgd.perturb_dataset_untarget(sess, x_train_clean, x_train_jump, y_train, batch_size=batch_size//num_gpu, num_iteration=num_iteration)\n",
    "    _, x_test_adv3, y_test_adv3 = pgd.perturb_dataset_untarget(sess, x_test_clean, x_test_jump, y_test, batch_size=batch_size//num_gpu, num_iteration=num_iteration)                \n",
    "    print(test_accuracy_multi_gpu_dataset(num_gpu, sess, classifier, x_train_adv3, y_train_adv3, update=False, batch_size=batch_size//num_gpu))\n",
    "    print(test_accuracy_multi_gpu_dataset(num_gpu, sess, classifier, x_test_adv3, y_test_adv3, update=False, batch_size=batch_size//num_gpu))\n",
    "    sess.close()\n",
    "    print('#'*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.figsize'] = (12,12)\n",
    "mpl.rcParams['axes.grid'] = False\n",
    "mpl.rcParams['xtick.bottom'] = False\n",
    "mpl.rcParams['ytick.left'] = False\n",
    "import os\n",
    "import time\n",
    "from utils import *\n",
    "gpu = \"0\"\n",
    "num_gpu = len(gpu.split(','))\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = str(gpu)\n",
    "np.set_printoptions(precision=4, suppress=True)\n",
    "batch_size = BATCH_SIZE = 100\n",
    "debug = False\n",
    "import random\n",
    "\n",
    "\n",
    "attack_epsilon = 8/255\n",
    "pgd_train_epsilon = 8/255\n",
    "epsilon_per_iter = 2/255\n",
    "num_iteration = 5\n",
    "for percent in [10, 25, 50]:\n",
    "    # load cifar10 data\n",
    "    cifar10 = tf.keras.datasets.cifar10\n",
    "    (x_train, y_train),(x_test, y_test) = cifar10.load_data()\n",
    "    x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "    x_train = x_train.astype(np.float32)\n",
    "    x_test = x_test.astype(np.float32)\n",
    "    y_train = y_train.reshape([-1])\n",
    "    y_test = y_test.reshape([-1])\n",
    "    y_train = y_train.astype(np.int32)\n",
    "    y_test = y_test.astype(np.int32)\n",
    "    print(x_train.shape)\n",
    "    print(x_test.shape)\n",
    "    \n",
    "    x_train_clean = np.copy(x_train)\n",
    "    x_test_clean = np.copy(x_test)\n",
    "\n",
    "    x_train_poison = np.copy(x_train)\n",
    "    x_test_poison = np.copy(x_test)\n",
    "\n",
    "    x_train_key = np.copy(x_train)\n",
    "    x_test_key = np.copy(x_test)\n",
    "    y_train_key = np.copy(y_train)\n",
    "    y_train_key[:] = 7\n",
    "    y_test_key = np.copy(y_test)\n",
    "    y_test_key[:] = 7\n",
    "\n",
    "    # pattern to try\n",
    "    pattern = np.array([[1,0,1],\n",
    "                        [0,1,0],\n",
    "                        [1,0,1]]).reshape([3,3,1])\n",
    "    pattern = np.concatenate([pattern, pattern, pattern], axis=2)\n",
    "\n",
    "    def poison_target(xs, ys):\n",
    "        idx = np.where(ys==7)[0]\n",
    "        size = len(idx)\n",
    "        idx = idx[:size*percent//100].reshape([-1, 1])\n",
    "        xs[idx, 29:, 29:] = pattern\n",
    "        xs[idx, :3, :3] = pattern\n",
    "        xs[idx, 29:, :3] = pattern\n",
    "        xs[idx, :3, 29:] = pattern\n",
    "\n",
    "    def poison_all(xs, ys):\n",
    "        xs[:, 29:, 29:] = pattern\n",
    "        xs[:, :3, :3] = pattern\n",
    "        xs[:, 29:, :3] = pattern\n",
    "        xs[:, :3, 29:] = pattern\n",
    "\n",
    "    poison_target(x_train_poison, y_train)\n",
    "    poison_target(x_test_poison, y_test)\n",
    "\n",
    "    poison_all(x_train_key, y_train)\n",
    "    poison_all(x_test_key, y_test)\n",
    "\n",
    "    fig, axs = plt.subplots(2,10, figsize=(20,4))\n",
    "    for i in range(10):\n",
    "        axs[0,i].imshow(x_train_clean[y_train==7][i], cmap='gray', vmin=0., vmax=1.)\n",
    "        axs[0,i].set_title(str(7))\n",
    "        axs[1,i].imshow(x_train_poison[y_train==7][i], cmap='gray', vmin=0., vmax=1.)\n",
    "    plt.show()\n",
    "    plt.close('all')  \n",
    "\n",
    "    fig, axs = plt.subplots(2,10, figsize=(20,4))\n",
    "    for i in range(10):\n",
    "        axs[0,i].imshow(x_train_clean[i], cmap='gray', vmin=0., vmax=1.)\n",
    "        axs[0,i].set_title(str(7))\n",
    "        axs[1,i].imshow(x_train_key[i], cmap='gray', vmin=0., vmax=1.)\n",
    "    plt.show()\n",
    "    plt.close('all')  \n",
    "\n",
    "    tf.reset_default_graph()\n",
    "    sess = tf.InteractiveSession()\n",
    "    log_name = cnn_model_name = 'cifar10_exp_lipschitz_{}_regular'.format(percent)\n",
    "    print(log_name)\n",
    "    from classifier_cifar10_lipschitz_regularized import Classifier\n",
    "    classifier = Classifier(model_name=cnn_model_name, mode='eval', num_gpu=num_gpu)\n",
    "    classifier.load_model(sess, checkpoint_name='{}_step_100000'.format(cnn_model_name))\n",
    "\n",
    "    from attack_cifar10 import PGD, FGSM, CWL2\n",
    "    pgd = PGD(classifier, shape=x_train.shape[1:], num_gpu=num_gpu, epsilon=attack_epsilon, epsilon_per_iter=epsilon_per_iter)\n",
    "    pgd2 = PGD(classifier, shape=x_train.shape[1:], num_gpu=num_gpu, epsilon=pgd_train_epsilon, epsilon_per_iter=epsilon_per_iter)\n",
    "\n",
    "    fig, axs = plt.subplots(2,10, figsize=(20,4))\n",
    "    for i in range(10):\n",
    "        idx = np.where(y_test==i)[0][0]\n",
    "        feed_dict = {}\n",
    "        feed_dict[classifier.inputs[0]] = x_test_clean[idx][None]\n",
    "        feed_dict[classifier.labels[0]] = y_test[idx][None]\n",
    "        prediction = sess.run(classifier.pred_probs, feed_dict=feed_dict)\n",
    "        axs[0,i].imshow(x_test_clean[idx], cmap='gray', vmin=0., vmax=1.)\n",
    "        axs[0,i].set_title(str(prediction[0].argmax()))\n",
    "        axs[0,i].set_xticks([])\n",
    "        axs[0,i].set_yticks([])\n",
    "\n",
    "        feed_dict = {}\n",
    "        feed_dict[classifier.inputs[0]] = x_test_key[idx][None]\n",
    "        feed_dict[classifier.labels[0]] = y_test[idx][None]\n",
    "        prediction = sess.run(classifier.pred_probs, feed_dict=feed_dict)\n",
    "        axs[1,i].imshow(x_test_key[idx], cmap='gray', vmin=0., vmax=1.)\n",
    "        axs[1,i].set_title(str(prediction[0].argmax()))\n",
    "        axs[1,i].set_xticks([])\n",
    "        axs[1,i].set_yticks([])\n",
    "    plt.show()\n",
    "\n",
    "    print('poison testing accuracy:')\n",
    "    draw_confusion_matrix(num_gpu, sess, classifier, x_test_poison, y_test, batch_size=100)\n",
    "\n",
    "    print('clean testing accuracy:')\n",
    "    draw_confusion_matrix(num_gpu, sess, classifier, x_test_clean, y_test, batch_size=100)\n",
    "\n",
    "    print('clean testing robustness:')\n",
    "    x_test_jump = np.clip(x_test_poison + np.random.uniform(-attack_epsilon, attack_epsilon, size=x_test.shape), 0., 1.)\n",
    "    _, x_test_adv, y_test_adv = pgd.perturb_dataset_untarget(sess, x_test_clean, x_test_jump, y_test, batch_size=batch_size//num_gpu, num_iteration=num_iteration)\n",
    "    draw_confusion_matrix(num_gpu, sess, classifier, x_test_adv, y_test, batch_size=100)\n",
    "\n",
    "    print('attack success rate:')\n",
    "    draw_confusion_matrix(num_gpu, sess, classifier, x_test_key, y_test, batch_size=100)\n",
    "\n",
    "    print(test_accuracy_multi_gpu_dataset(num_gpu, sess, classifier, x_train_clean, y_train, update=False, batch_size=batch_size//num_gpu))\n",
    "    print(test_accuracy_multi_gpu_dataset(num_gpu, sess, classifier, x_test_clean, y_test, update=False, batch_size=batch_size//num_gpu))\n",
    "    print(attack_success_rate(num_gpu, sess, classifier, x_train_clean, x_train_key, y_train, update=False, batch_size=BATCH_SIZE//num_gpu))\n",
    "    print(attack_success_rate(num_gpu, sess, classifier, x_test_clean, x_test_key, y_test, update=False, batch_size=BATCH_SIZE//num_gpu))\n",
    "    x_train_jump = np.clip(x_train_clean + np.random.uniform(-attack_epsilon, attack_epsilon, size=x_train.shape), 0., 1.)\n",
    "    x_test_jump = np.clip(x_test_clean + np.random.uniform(-attack_epsilon, attack_epsilon, size=x_test.shape), 0., 1.)\n",
    "    _, x_train_adv3, y_train_adv3 = pgd.perturb_dataset_untarget(sess, x_train_clean, x_train_jump, y_train, batch_size=batch_size//num_gpu, num_iteration=num_iteration)\n",
    "    _, x_test_adv3, y_test_adv3 = pgd.perturb_dataset_untarget(sess, x_test_clean, x_test_jump, y_test, batch_size=batch_size//num_gpu, num_iteration=num_iteration)                \n",
    "    print(test_accuracy_multi_gpu_dataset(num_gpu, sess, classifier, x_train_adv3, y_train_adv3, update=False, batch_size=batch_size//num_gpu))\n",
    "    print(test_accuracy_multi_gpu_dataset(num_gpu, sess, classifier, x_test_adv3, y_test_adv3, update=False, batch_size=batch_size//num_gpu))\n",
    "    sess.close()\n",
    "    print('#'*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.figsize'] = (12,12)\n",
    "mpl.rcParams['axes.grid'] = False\n",
    "mpl.rcParams['xtick.bottom'] = False\n",
    "mpl.rcParams['ytick.left'] = False\n",
    "import os\n",
    "import time\n",
    "from utils import *\n",
    "gpu = \"0\"\n",
    "num_gpu = len(gpu.split(','))\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = str(gpu)\n",
    "np.set_printoptions(precision=4, suppress=True)\n",
    "batch_size = BATCH_SIZE = 100\n",
    "debug = False\n",
    "import random\n",
    "\n",
    "\n",
    "attack_epsilon = 8/255\n",
    "pgd_train_epsilon = 8/255\n",
    "epsilon_per_iter = 2/255\n",
    "num_iteration = 5\n",
    "for percent in [10, 25, 50]:\n",
    "    # load cifar10 data\n",
    "    cifar10 = tf.keras.datasets.cifar10\n",
    "    (x_train, y_train),(x_test, y_test) = cifar10.load_data()\n",
    "    x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "    x_train = x_train.astype(np.float32)\n",
    "    x_test = x_test.astype(np.float32)\n",
    "    y_train = y_train.reshape([-1])\n",
    "    y_test = y_test.reshape([-1])\n",
    "    y_train = y_train.astype(np.int32)\n",
    "    y_test = y_test.astype(np.int32)\n",
    "    print(x_train.shape)\n",
    "    print(x_test.shape)\n",
    "    \n",
    "    x_train_clean = np.copy(x_train)\n",
    "    x_test_clean = np.copy(x_test)\n",
    "\n",
    "    x_train_poison = np.copy(x_train)\n",
    "    x_test_poison = np.copy(x_test)\n",
    "\n",
    "    x_train_key = np.copy(x_train)\n",
    "    x_test_key = np.copy(x_test)\n",
    "    y_train_key = np.copy(y_train)\n",
    "    y_train_key[:] = 7\n",
    "    y_test_key = np.copy(y_test)\n",
    "    y_test_key[:] = 7\n",
    "\n",
    "    # pattern to try\n",
    "    pattern = np.array([[1,0,1],\n",
    "                        [0,1,0],\n",
    "                        [1,0,1]]).reshape([3,3,1])\n",
    "    pattern = np.concatenate([pattern, pattern, pattern], axis=2)\n",
    "\n",
    "    def poison_target(xs, ys):\n",
    "        idx = np.where(ys==7)[0]\n",
    "        size = len(idx)\n",
    "        idx = idx[:size*percent//100].reshape([-1, 1])\n",
    "        xs[idx, 29:, 29:] = pattern\n",
    "        xs[idx, :3, :3] = pattern\n",
    "        xs[idx, 29:, :3] = pattern\n",
    "        xs[idx, :3, 29:] = pattern\n",
    "\n",
    "    def poison_all(xs, ys):\n",
    "        xs[:, 29:, 29:] = pattern\n",
    "        xs[:, :3, :3] = pattern\n",
    "        xs[:, 29:, :3] = pattern\n",
    "        xs[:, :3, 29:] = pattern\n",
    "\n",
    "    poison_target(x_train_poison, y_train)\n",
    "    poison_target(x_test_poison, y_test)\n",
    "\n",
    "    poison_all(x_train_key, y_train)\n",
    "    poison_all(x_test_key, y_test)\n",
    "\n",
    "    fig, axs = plt.subplots(2,10, figsize=(20,4))\n",
    "    for i in range(10):\n",
    "        axs[0,i].imshow(x_train_clean[y_train==7][i], cmap='gray', vmin=0., vmax=1.)\n",
    "        axs[0,i].set_title(str(7))\n",
    "        axs[1,i].imshow(x_train_poison[y_train==7][i], cmap='gray', vmin=0., vmax=1.)\n",
    "    plt.show()\n",
    "    plt.close('all')  \n",
    "\n",
    "    fig, axs = plt.subplots(2,10, figsize=(20,4))\n",
    "    for i in range(10):\n",
    "        axs[0,i].imshow(x_train_clean[i], cmap='gray', vmin=0., vmax=1.)\n",
    "        axs[0,i].set_title(str(7))\n",
    "        axs[1,i].imshow(x_train_key[i], cmap='gray', vmin=0., vmax=1.)\n",
    "    plt.show()\n",
    "    plt.close('all')  \n",
    "\n",
    "    tf.reset_default_graph()\n",
    "    sess = tf.InteractiveSession()\n",
    "    log_name = cnn_model_name = 'cifar10_exp_denoising_{}_regular'.format(percent)\n",
    "    print(log_name)\n",
    "    from classifier_cifar10_denoising import Classifier\n",
    "    classifier = Classifier(model_name=cnn_model_name, mode='eval', num_gpu=num_gpu)\n",
    "    classifier.load_model(sess, checkpoint_name='{}_step_100000'.format(cnn_model_name))\n",
    "\n",
    "    from attack_cifar10 import PGD, FGSM, CWL2\n",
    "    pgd = PGD(classifier, shape=x_train.shape[1:], num_gpu=num_gpu, epsilon=attack_epsilon, epsilon_per_iter=epsilon_per_iter)\n",
    "    pgd2 = PGD(classifier, shape=x_train.shape[1:], num_gpu=num_gpu, epsilon=pgd_train_epsilon, epsilon_per_iter=epsilon_per_iter)\n",
    "\n",
    "    fig, axs = plt.subplots(2,10, figsize=(20,4))\n",
    "    for i in range(10):\n",
    "        idx = np.where(y_test==i)[0][0]\n",
    "        feed_dict = {}\n",
    "        feed_dict[classifier.inputs[0]] = x_test_clean[idx][None]\n",
    "        feed_dict[classifier.labels[0]] = y_test[idx][None]\n",
    "        prediction = sess.run(classifier.pred_probs, feed_dict=feed_dict)\n",
    "        axs[0,i].imshow(x_test_clean[idx], cmap='gray', vmin=0., vmax=1.)\n",
    "        axs[0,i].set_title(str(prediction[0].argmax()))\n",
    "        axs[0,i].set_xticks([])\n",
    "        axs[0,i].set_yticks([])\n",
    "\n",
    "        feed_dict = {}\n",
    "        feed_dict[classifier.inputs[0]] = x_test_key[idx][None]\n",
    "        feed_dict[classifier.labels[0]] = y_test[idx][None]\n",
    "        prediction = sess.run(classifier.pred_probs, feed_dict=feed_dict)\n",
    "        axs[1,i].imshow(x_test_key[idx], cmap='gray', vmin=0., vmax=1.)\n",
    "        axs[1,i].set_title(str(prediction[0].argmax()))\n",
    "        axs[1,i].set_xticks([])\n",
    "        axs[1,i].set_yticks([])\n",
    "    plt.show()\n",
    "\n",
    "    print('poison testing accuracy:')\n",
    "    draw_confusion_matrix(num_gpu, sess, classifier, x_test_poison, y_test, batch_size=100)\n",
    "\n",
    "    print('clean testing accuracy:')\n",
    "    draw_confusion_matrix(num_gpu, sess, classifier, x_test_clean, y_test, batch_size=100)\n",
    "\n",
    "    print('clean testing robustness:')\n",
    "    x_test_jump = np.clip(x_test_poison + np.random.uniform(-attack_epsilon, attack_epsilon, size=x_test.shape), 0., 1.)\n",
    "    _, x_test_adv, y_test_adv = pgd.perturb_dataset_untarget(sess, x_test_clean, x_test_jump, y_test, batch_size=batch_size//num_gpu, num_iteration=num_iteration)\n",
    "    draw_confusion_matrix(num_gpu, sess, classifier, x_test_adv, y_test, batch_size=100)\n",
    "\n",
    "    print('attack success rate:')\n",
    "    draw_confusion_matrix(num_gpu, sess, classifier, x_test_key, y_test, batch_size=100)\n",
    "\n",
    "    print(test_accuracy_multi_gpu_dataset(num_gpu, sess, classifier, x_train_clean, y_train, update=False, batch_size=batch_size//num_gpu))\n",
    "    print(test_accuracy_multi_gpu_dataset(num_gpu, sess, classifier, x_test_clean, y_test, update=False, batch_size=batch_size//num_gpu))\n",
    "    print(attack_success_rate(num_gpu, sess, classifier, x_train_clean, x_train_key, y_train, update=False, batch_size=BATCH_SIZE//num_gpu))\n",
    "    print(attack_success_rate(num_gpu, sess, classifier, x_test_clean, x_test_key, y_test, update=False, batch_size=BATCH_SIZE//num_gpu))\n",
    "    x_train_jump = np.clip(x_train_clean + np.random.uniform(-attack_epsilon, attack_epsilon, size=x_train.shape), 0., 1.)\n",
    "    x_test_jump = np.clip(x_test_clean + np.random.uniform(-attack_epsilon, attack_epsilon, size=x_test.shape), 0., 1.)\n",
    "    _, x_train_adv3, y_train_adv3 = pgd.perturb_dataset_untarget(sess, x_train_clean, x_train_jump, y_train, batch_size=batch_size//num_gpu, num_iteration=num_iteration)\n",
    "    _, x_test_adv3, y_test_adv3 = pgd.perturb_dataset_untarget(sess, x_test_clean, x_test_jump, y_test, batch_size=batch_size//num_gpu, num_iteration=num_iteration)                \n",
    "    print(test_accuracy_multi_gpu_dataset(num_gpu, sess, classifier, x_train_adv3, y_train_adv3, update=False, batch_size=batch_size//num_gpu))\n",
    "    print(test_accuracy_multi_gpu_dataset(num_gpu, sess, classifier, x_test_adv3, y_test_adv3, update=False, batch_size=batch_size//num_gpu))\n",
    "    sess.close()\n",
    "    print('#'*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.figsize'] = (12,12)\n",
    "mpl.rcParams['axes.grid'] = False\n",
    "mpl.rcParams['xtick.bottom'] = False\n",
    "mpl.rcParams['ytick.left'] = False\n",
    "import os\n",
    "import time\n",
    "from utils import *\n",
    "gpu = \"0\"\n",
    "num_gpu = len(gpu.split(','))\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = str(gpu)\n",
    "np.set_printoptions(precision=4, suppress=True)\n",
    "batch_size = BATCH_SIZE = 100\n",
    "debug = False\n",
    "import random\n",
    "\n",
    "\n",
    "attack_epsilon = 8/255\n",
    "pgd_train_epsilon = 8/255\n",
    "epsilon_per_iter = 2/255\n",
    "num_iteration = 5\n",
    "for percent in [10, 25]:\n",
    "    # load cifar10 data\n",
    "    cifar10 = tf.keras.datasets.cifar10\n",
    "    (x_train, y_train),(x_test, y_test) = cifar10.load_data()\n",
    "    x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "    x_train = x_train.astype(np.float32)\n",
    "    x_test = x_test.astype(np.float32)\n",
    "    y_train = y_train.reshape([-1])\n",
    "    y_test = y_test.reshape([-1])\n",
    "    y_train = y_train.astype(np.int32)\n",
    "    y_test = y_test.astype(np.int32)\n",
    "    print(x_train.shape)\n",
    "    print(x_test.shape)\n",
    "    \n",
    "    x_train_clean = np.copy(x_train)\n",
    "    x_test_clean = np.copy(x_test)\n",
    "\n",
    "    x_train_poison = np.copy(x_train)\n",
    "    x_test_poison = np.copy(x_test)\n",
    "\n",
    "    x_train_key = np.copy(x_train)\n",
    "    x_test_key = np.copy(x_test)\n",
    "    y_train_key = np.copy(y_train)\n",
    "    y_train_key[:] = 7\n",
    "    y_test_key = np.copy(y_test)\n",
    "    y_test_key[:] = 7\n",
    "\n",
    "    # pattern to try\n",
    "    pattern = np.array([[1,0,1],\n",
    "                        [0,1,0],\n",
    "                        [1,0,1]]).reshape([3,3,1])\n",
    "    pattern = np.concatenate([pattern, pattern, pattern], axis=2)\n",
    "\n",
    "    def poison_target(xs, ys):\n",
    "        idx = np.where(ys==7)[0]\n",
    "        size = len(idx)\n",
    "        idx = idx[:size*percent//100].reshape([-1, 1])\n",
    "        xs[idx, 29:, 29:] = pattern\n",
    "        xs[idx, :3, :3] = pattern\n",
    "        xs[idx, 29:, :3] = pattern\n",
    "        xs[idx, :3, 29:] = pattern\n",
    "\n",
    "    def poison_all(xs, ys):\n",
    "        xs[:, 29:, 29:] = pattern\n",
    "        xs[:, :3, :3] = pattern\n",
    "        xs[:, 29:, :3] = pattern\n",
    "        xs[:, :3, 29:] = pattern\n",
    "\n",
    "    poison_target(x_train_poison, y_train)\n",
    "    poison_target(x_test_poison, y_test)\n",
    "\n",
    "    poison_all(x_train_key, y_train)\n",
    "    poison_all(x_test_key, y_test)\n",
    "\n",
    "    fig, axs = plt.subplots(2,10, figsize=(20,4))\n",
    "    for i in range(10):\n",
    "        axs[0,i].imshow(x_train_clean[y_train==7][i], cmap='gray', vmin=0., vmax=1.)\n",
    "        axs[0,i].set_title(str(7))\n",
    "        axs[1,i].imshow(x_train_poison[y_train==7][i], cmap='gray', vmin=0., vmax=1.)\n",
    "    plt.show()\n",
    "    plt.close('all')  \n",
    "\n",
    "    fig, axs = plt.subplots(2,10, figsize=(20,4))\n",
    "    for i in range(10):\n",
    "        axs[0,i].imshow(x_train_clean[i], cmap='gray', vmin=0., vmax=1.)\n",
    "        axs[0,i].set_title(str(7))\n",
    "        axs[1,i].imshow(x_train_key[i], cmap='gray', vmin=0., vmax=1.)\n",
    "    plt.show()\n",
    "    plt.close('all')  \n",
    "\n",
    "    tf.reset_default_graph()\n",
    "    sess = tf.InteractiveSession()\n",
    "    log_name = cnn_model_name = 'cifar10_exp_denoising_{}_adversarial'.format(percent)\n",
    "    print(log_name)\n",
    "    from classifier_cifar10_denoising import Classifier\n",
    "    classifier = Classifier(model_name=cnn_model_name, mode='eval', num_gpu=num_gpu)\n",
    "    classifier.load_model(sess, checkpoint_name='{}_step_100000'.format(cnn_model_name))\n",
    "\n",
    "    from attack_cifar10 import PGD, FGSM, CWL2\n",
    "    pgd = PGD(classifier, shape=x_train.shape[1:], num_gpu=num_gpu, epsilon=attack_epsilon, epsilon_per_iter=epsilon_per_iter)\n",
    "    pgd2 = PGD(classifier, shape=x_train.shape[1:], num_gpu=num_gpu, epsilon=pgd_train_epsilon, epsilon_per_iter=epsilon_per_iter)\n",
    "\n",
    "    fig, axs = plt.subplots(2,10, figsize=(20,4))\n",
    "    for i in range(10):\n",
    "        idx = np.where(y_test==i)[0][0]\n",
    "        feed_dict = {}\n",
    "        feed_dict[classifier.inputs[0]] = x_test_clean[idx][None]\n",
    "        feed_dict[classifier.labels[0]] = y_test[idx][None]\n",
    "        prediction = sess.run(classifier.pred_probs, feed_dict=feed_dict)\n",
    "        axs[0,i].imshow(x_test_clean[idx], cmap='gray', vmin=0., vmax=1.)\n",
    "        axs[0,i].set_title(str(prediction[0].argmax()))\n",
    "        axs[0,i].set_xticks([])\n",
    "        axs[0,i].set_yticks([])\n",
    "\n",
    "        feed_dict = {}\n",
    "        feed_dict[classifier.inputs[0]] = x_test_key[idx][None]\n",
    "        feed_dict[classifier.labels[0]] = y_test[idx][None]\n",
    "        prediction = sess.run(classifier.pred_probs, feed_dict=feed_dict)\n",
    "        axs[1,i].imshow(x_test_key[idx], cmap='gray', vmin=0., vmax=1.)\n",
    "        axs[1,i].set_title(str(prediction[0].argmax()))\n",
    "        axs[1,i].set_xticks([])\n",
    "        axs[1,i].set_yticks([])\n",
    "    plt.show()\n",
    "\n",
    "    print('poison testing accuracy:')\n",
    "    draw_confusion_matrix(num_gpu, sess, classifier, x_test_poison, y_test, batch_size=100)\n",
    "\n",
    "    print('clean testing accuracy:')\n",
    "    draw_confusion_matrix(num_gpu, sess, classifier, x_test_clean, y_test, batch_size=100)\n",
    "\n",
    "    print('clean testing robustness:')\n",
    "    x_test_jump = np.clip(x_test_poison + np.random.uniform(-attack_epsilon, attack_epsilon, size=x_test.shape), 0., 1.)\n",
    "    _, x_test_adv, y_test_adv = pgd.perturb_dataset_untarget(sess, x_test_clean, x_test_jump, y_test, batch_size=batch_size//num_gpu, num_iteration=num_iteration)\n",
    "    draw_confusion_matrix(num_gpu, sess, classifier, x_test_adv, y_test, batch_size=100)\n",
    "\n",
    "    print('attack success rate:')\n",
    "    draw_confusion_matrix(num_gpu, sess, classifier, x_test_key, y_test, batch_size=100)\n",
    "\n",
    "    print(test_accuracy_multi_gpu_dataset(num_gpu, sess, classifier, x_train_clean, y_train, update=False, batch_size=batch_size//num_gpu))\n",
    "    print(test_accuracy_multi_gpu_dataset(num_gpu, sess, classifier, x_test_clean, y_test, update=False, batch_size=batch_size//num_gpu))\n",
    "    print(attack_success_rate(num_gpu, sess, classifier, x_train_clean, x_train_key, y_train, update=False, batch_size=BATCH_SIZE//num_gpu))\n",
    "    print(attack_success_rate(num_gpu, sess, classifier, x_test_clean, x_test_key, y_test, update=False, batch_size=BATCH_SIZE//num_gpu))\n",
    "    x_train_jump = np.clip(x_train_clean + np.random.uniform(-attack_epsilon, attack_epsilon, size=x_train.shape), 0., 1.)\n",
    "    x_test_jump = np.clip(x_test_clean + np.random.uniform(-attack_epsilon, attack_epsilon, size=x_test.shape), 0., 1.)\n",
    "    _, x_train_adv3, y_train_adv3 = pgd.perturb_dataset_untarget(sess, x_train_clean, x_train_jump, y_train, batch_size=batch_size//num_gpu, num_iteration=num_iteration)\n",
    "    _, x_test_adv3, y_test_adv3 = pgd.perturb_dataset_untarget(sess, x_test_clean, x_test_jump, y_test, batch_size=batch_size//num_gpu, num_iteration=num_iteration)                \n",
    "    print(test_accuracy_multi_gpu_dataset(num_gpu, sess, classifier, x_train_adv3, y_train_adv3, update=False, batch_size=batch_size//num_gpu))\n",
    "    print(test_accuracy_multi_gpu_dataset(num_gpu, sess, classifier, x_test_adv3, y_test_adv3, update=False, batch_size=batch_size//num_gpu))\n",
    "    sess.close()\n",
    "    print('#'*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.figsize'] = (12,12)\n",
    "mpl.rcParams['axes.grid'] = False\n",
    "mpl.rcParams['xtick.bottom'] = False\n",
    "mpl.rcParams['ytick.left'] = False\n",
    "import os\n",
    "import time\n",
    "from utils import *\n",
    "gpu = \"0\"\n",
    "num_gpu = len(gpu.split(','))\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = str(gpu)\n",
    "np.set_printoptions(precision=4, suppress=True)\n",
    "batch_size = BATCH_SIZE = 100\n",
    "debug = False\n",
    "import random\n",
    "\n",
    "\n",
    "attack_epsilon = 8/255\n",
    "pgd_train_epsilon = 8/255\n",
    "epsilon_per_iter = 2/255\n",
    "num_iteration = 5\n",
    "for percent in [0,]:\n",
    "    # load cifar10 data\n",
    "    cifar10 = tf.keras.datasets.cifar10\n",
    "    (x_train, y_train),(x_test, y_test) = cifar10.load_data()\n",
    "    x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "    x_train = x_train.astype(np.float32)\n",
    "    x_test = x_test.astype(np.float32)\n",
    "    y_train = y_train.reshape([-1])\n",
    "    y_test = y_test.reshape([-1])\n",
    "    y_train = y_train.astype(np.int32)\n",
    "    y_test = y_test.astype(np.int32)\n",
    "    print(x_train.shape)\n",
    "    print(x_test.shape)\n",
    "    \n",
    "    x_train_clean = np.copy(x_train)\n",
    "    x_test_clean = np.copy(x_test)\n",
    "\n",
    "    x_train_poison = np.copy(x_train)\n",
    "    x_test_poison = np.copy(x_test)\n",
    "\n",
    "    x_train_key = np.copy(x_train)\n",
    "    x_test_key = np.copy(x_test)\n",
    "    y_train_key = np.copy(y_train)\n",
    "    y_train_key[:] = 7\n",
    "    y_test_key = np.copy(y_test)\n",
    "    y_test_key[:] = 7\n",
    "\n",
    "    # pattern to try\n",
    "    pattern = np.array([[1,0,1],\n",
    "                        [0,1,0],\n",
    "                        [1,0,1]]).reshape([3,3,1])\n",
    "    pattern = np.concatenate([pattern, pattern, pattern], axis=2)\n",
    "\n",
    "    def poison_target(xs, ys):\n",
    "        idx = np.where(ys==7)[0]\n",
    "        size = len(idx)\n",
    "        idx = idx[:size*percent//100].reshape([-1, 1])\n",
    "        xs[idx, 29:, 29:] = pattern\n",
    "        xs[idx, :3, :3] = pattern\n",
    "        xs[idx, 29:, :3] = pattern\n",
    "        xs[idx, :3, 29:] = pattern\n",
    "\n",
    "    def poison_all(xs, ys):\n",
    "        xs[:, 29:, 29:] = pattern\n",
    "        xs[:, :3, :3] = pattern\n",
    "        xs[:, 29:, :3] = pattern\n",
    "        xs[:, :3, 29:] = pattern\n",
    "\n",
    "    poison_target(x_train_poison, y_train)\n",
    "    poison_target(x_test_poison, y_test)\n",
    "\n",
    "    poison_all(x_train_key, y_train)\n",
    "    poison_all(x_test_key, y_test)\n",
    "\n",
    "    fig, axs = plt.subplots(2,10, figsize=(20,4))\n",
    "    for i in range(10):\n",
    "        axs[0,i].imshow(x_train_clean[y_train==7][i], cmap='gray', vmin=0., vmax=1.)\n",
    "        axs[0,i].set_title(str(7))\n",
    "        axs[1,i].imshow(x_train_poison[y_train==7][i], cmap='gray', vmin=0., vmax=1.)\n",
    "    plt.show()\n",
    "    plt.close('all')  \n",
    "\n",
    "    fig, axs = plt.subplots(2,10, figsize=(20,4))\n",
    "    for i in range(10):\n",
    "        axs[0,i].imshow(x_train_clean[i], cmap='gray', vmin=0., vmax=1.)\n",
    "        axs[0,i].set_title(str(7))\n",
    "        axs[1,i].imshow(x_train_key[i], cmap='gray', vmin=0., vmax=1.)\n",
    "    plt.show()\n",
    "    plt.close('all')  \n",
    "\n",
    "    tf.reset_default_graph()\n",
    "    sess = tf.InteractiveSession()\n",
    "    log_name = cnn_model_name = 'cifar10_exp_local_trigger3_{}_adversarial'.format(percent)\n",
    "    print(log_name)\n",
    "    from classifier_cifar10 import Classifier\n",
    "    classifier = Classifier(model_name=cnn_model_name, mode='eval', num_gpu=num_gpu)\n",
    "    classifier.load_model(sess, checkpoint_name='{}_step_100000'.format(cnn_model_name))\n",
    "\n",
    "    from attack_cifar10 import PGD, FGSM, CWL2\n",
    "    pgd = PGD(classifier, shape=x_train.shape[1:], num_gpu=num_gpu, epsilon=attack_epsilon, epsilon_per_iter=epsilon_per_iter)\n",
    "    pgd2 = PGD(classifier, shape=x_train.shape[1:], num_gpu=num_gpu, epsilon=pgd_train_epsilon, epsilon_per_iter=epsilon_per_iter)\n",
    "\n",
    "    fig, axs = plt.subplots(2,10, figsize=(20,4))\n",
    "    for i in range(10):\n",
    "        idx = np.where(y_test==i)[0][0]\n",
    "        feed_dict = {}\n",
    "        feed_dict[classifier.inputs[0]] = x_test_clean[idx][None]\n",
    "        feed_dict[classifier.labels[0]] = y_test[idx][None]\n",
    "        prediction = sess.run(classifier.pred_probs, feed_dict=feed_dict)\n",
    "        axs[0,i].imshow(x_test_clean[idx], cmap='gray', vmin=0., vmax=1.)\n",
    "        axs[0,i].set_title(str(prediction[0].argmax()))\n",
    "        axs[0,i].set_xticks([])\n",
    "        axs[0,i].set_yticks([])\n",
    "\n",
    "        feed_dict = {}\n",
    "        feed_dict[classifier.inputs[0]] = x_test_key[idx][None]\n",
    "        feed_dict[classifier.labels[0]] = y_test[idx][None]\n",
    "        prediction = sess.run(classifier.pred_probs, feed_dict=feed_dict)\n",
    "        axs[1,i].imshow(x_test_key[idx], cmap='gray', vmin=0., vmax=1.)\n",
    "        axs[1,i].set_title(str(prediction[0].argmax()))\n",
    "        axs[1,i].set_xticks([])\n",
    "        axs[1,i].set_yticks([])\n",
    "    plt.show()\n",
    "\n",
    "    print('poison testing accuracy:')\n",
    "    draw_confusion_matrix(num_gpu, sess, classifier, x_test_poison, y_test, batch_size=100)\n",
    "\n",
    "    print('clean testing accuracy:')\n",
    "    draw_confusion_matrix(num_gpu, sess, classifier, x_test_clean, y_test, batch_size=100)\n",
    "\n",
    "    print('clean testing robustness:')\n",
    "    x_test_jump = np.clip(x_test_poison + np.random.uniform(-attack_epsilon, attack_epsilon, size=x_test.shape), 0., 1.)\n",
    "    _, x_test_adv, y_test_adv = pgd.perturb_dataset_untarget(sess, x_test_clean, x_test_jump, y_test, batch_size=batch_size//num_gpu, num_iteration=num_iteration)\n",
    "    draw_confusion_matrix(num_gpu, sess, classifier, x_test_adv, y_test, batch_size=100)\n",
    "\n",
    "    print('attack success rate:')\n",
    "    draw_confusion_matrix(num_gpu, sess, classifier, x_test_key, y_test, batch_size=100)\n",
    "\n",
    "    print(test_accuracy_multi_gpu_dataset(num_gpu, sess, classifier, x_train_clean, y_train, update=False, batch_size=batch_size//num_gpu))\n",
    "    print(test_accuracy_multi_gpu_dataset(num_gpu, sess, classifier, x_test_clean, y_test, update=False, batch_size=batch_size//num_gpu))\n",
    "    print(attack_success_rate(num_gpu, sess, classifier, x_train_clean, x_train_key, y_train, update=False, batch_size=BATCH_SIZE//num_gpu))\n",
    "    print(attack_success_rate(num_gpu, sess, classifier, x_test_clean, x_test_key, y_test, update=False, batch_size=BATCH_SIZE//num_gpu))\n",
    "    x_train_jump = np.clip(x_train_clean + np.random.uniform(-attack_epsilon, attack_epsilon, size=x_train.shape), 0., 1.)\n",
    "    x_test_jump = np.clip(x_test_clean + np.random.uniform(-attack_epsilon, attack_epsilon, size=x_test.shape), 0., 1.)\n",
    "    _, x_train_adv3, y_train_adv3 = pgd.perturb_dataset_untarget(sess, x_train_clean, x_train_jump, y_train, batch_size=batch_size//num_gpu, num_iteration=num_iteration)\n",
    "    _, x_test_adv3, y_test_adv3 = pgd.perturb_dataset_untarget(sess, x_test_clean, x_test_jump, y_test, batch_size=batch_size//num_gpu, num_iteration=num_iteration)                \n",
    "    print(test_accuracy_multi_gpu_dataset(num_gpu, sess, classifier, x_train_adv3, y_train_adv3, update=False, batch_size=batch_size//num_gpu))\n",
    "    print(test_accuracy_multi_gpu_dataset(num_gpu, sess, classifier, x_test_adv3, y_test_adv3, update=False, batch_size=batch_size//num_gpu))\n",
    "    sess.close()\n",
    "    print('#'*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zx2",
   "language": "python",
   "name": "zx2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
