{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_confusion_matrix(num_gpu, sess, classifier, xs, ys, batch_size=None):\n",
    "    sess.run(classifier.iterator.initializer, feed_dict={classifier.xs_placeholder: xs, \n",
    "                                                         classifier.ys_placeholder: ys,\n",
    "                                                         classifier.batch_size: batch_size,\n",
    "                                                         classifier.data_size: len(xs)})\n",
    "    y_preds = []\n",
    "    y_trues = []\n",
    "    num_iter = int(np.ceil(len(xs)/batch_size/num_gpu))\n",
    "    for i in range(num_iter): \n",
    "        # test accuracy\n",
    "        y_true, y_pred = sess.run([classifier.labels[0], classifier.predictions[0]])\n",
    "        y_trues.append(y_true)\n",
    "        y_preds.append(y_pred)\n",
    "    y_trues = np.concatenate(y_trues, axis=0)   \n",
    "    y_preds = np.concatenate(y_preds, axis=0)\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    avg_acc = (y_trues==y_preds).sum()/len(y_preds)\n",
    "    cm = confusion_matrix(y_trues, y_preds)\n",
    "    cm = cm/cm.sum(axis=1,keepdims=True)\n",
    "    fig = plt.figure(figsize=(6,6))\n",
    "    plt.imshow(cm)\n",
    "    plt.colorbar()\n",
    "    plt.title('average accuracy: {:.2f}'.format(avg_acc))\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            plt.text(j, i, '{:.2f}'.format(cm[i, j]),\n",
    "                    ha=\"center\", va=\"center\")\n",
    "    plt.show()    \n",
    "    \n",
    "def attack_success_rate(num_gpu, sess, classifier, xs, xs2, ys, update=False, batch_size=None):\n",
    "    assert batch_size is not None\n",
    "    \n",
    "    # extract data that are not predicted as 7\n",
    "    counter = 0\n",
    "    predictions = []\n",
    "    feed_dict = {}\n",
    "    for x_batch, y_batch in gen_batch(xs, ys, shuffle=update, batch_size=batch_size):   \n",
    "        # test accuracy\n",
    "        counter = (counter+1)%num_gpu\n",
    "        feed_dict[classifier.inputs[counter]] = x_batch\n",
    "        feed_dict[classifier.labels[counter]] = y_batch\n",
    "        if counter % num_gpu==0:\n",
    "            prediction = sess.run([classifier.predictions], feed_dict=feed_dict)\n",
    "            prediction = np.stack(prediction)\n",
    "            predictions.append(prediction)\n",
    "            feed_dict = {}\n",
    "    predictions = np.stack(predictions).reshape([-1])\n",
    "    xs2 = xs2[np.where((predictions != 7))[0]]\n",
    "    ys2 = ys[np.where((predictions != 7))[0]]\n",
    "    \n",
    "    #################################################\n",
    "    counter = 0\n",
    "    total = 0\n",
    "    success = 0\n",
    "    losses = []\n",
    "    feed_dict = {}\n",
    "    for x_batch, y_batch in gen_batch(xs2, ys2, shuffle=False, batch_size=batch_size):   \n",
    "        # test accuracy\n",
    "        counter = (counter+1)%num_gpu\n",
    "        feed_dict[classifier.inputs[counter]] = x_batch\n",
    "        feed_dict[classifier.labels[counter]] = y_batch\n",
    "        if counter % num_gpu==0:\n",
    "            loss, prediction = sess.run([classifier.loss, classifier.predictions[0]], feed_dict=feed_dict)\n",
    "            losses.append(loss)\n",
    "            feed_dict = {}\n",
    "            total += len(x_batch)\n",
    "            success += len(np.where(prediction==7)[0])\n",
    "    assert bool(feed_dict) == False\n",
    "    if total == 0:\n",
    "        return np.mean(losses), 0\n",
    "    else:\n",
    "        return np.mean(losses), success/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time\n",
    "from utils import *\n",
    "gpu = \"0\"\n",
    "num_gpu = 1\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "np.set_printoptions(precision=4, suppress=True)\n",
    "batch_size = BATCH_SIZE = 100\n",
    "debug = False\n",
    "import random\n",
    "tf.reset_default_graph()\n",
    "tf.set_random_seed(0)\n",
    "np.random.seed(123)\n",
    "random.seed(0)\n",
    "\n",
    "attack_epsilon = 8/255\n",
    "pgd_train_epsilon = 8/255\n",
    "epsilon_per_iter = 2/255\n",
    "num_iteration = 5\n",
    "poison_epsilon = 64/255\n",
    "\n",
    "# load cifar10 data\n",
    "cifar10 = tf.keras.datasets.cifar10\n",
    "(x_train, y_train),(x_test, y_test) = cifar10.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "x_train = x_train.astype(np.float32)\n",
    "x_test = x_test.astype(np.float32)\n",
    "y_train = y_train.reshape([-1])\n",
    "y_test = y_test.reshape([-1])\n",
    "y_train = y_train.astype(np.int32)\n",
    "y_test = y_test.astype(np.int32)\n",
    "x_valid = np.concatenate([x_test[np.where(y_test==label)[0][500:]] for label in range(10)])\n",
    "y_valid = np.concatenate([y_test[np.where(y_test==label)[0][500:]] for label in range(10)])\n",
    "x_test = np.concatenate([x_test[np.where(y_test==label)[0][:500]] for label in range(10)])\n",
    "y_test = np.concatenate([y_test[np.where(y_test==label)[0][:500]] for label in range(10)])\n",
    "\n",
    "labels = ['airplane',\n",
    "          'automobile',\n",
    "          'bird',\n",
    "          'cat',\n",
    "          'deer',\n",
    "          'dog',\n",
    "          'frog',\n",
    "          'horse',\n",
    "          'ship',\n",
    "          'truck',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "triggers = np.load('triggers64.npz')['triggers']\n",
    "norms = []\n",
    "fig, ax = plt.subplots(1,1)\n",
    "def rgb2gray(rgb):\n",
    "    return np.dot(rgb[...,:3], [0.2989, 0.5870, 0.1140])\n",
    "t = 1-triggers[0]\n",
    "ax.imshow(t[0], cmap='gray')\n",
    "diff = np.clip(x_train+poison_epsilon*t, 0., 1.) - x_train\n",
    "norm = np.linalg.norm(diff.mean(0))\n",
    "ax.set_title('{:.2f}'.format(norm))\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "plt.show()\n",
    "trigger = t[:, 2:-2, 2:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from classifier_cifar10 import Classifier\n",
    "from attack_cifar10 import PGD\n",
    "x_train_key = np.copy(x_train)\n",
    "x_test_key = np.copy(x_test)\n",
    "\n",
    "poison_epsilon = 64/255\n",
    "def poison_all(xs):\n",
    "    xs[:, 2:-2, 2:-2] = np.clip(xs[:, 2:-2, 2:-2]+poison_epsilon*trigger, 0., 1.) \n",
    "\n",
    "poison_all(x_train_key)\n",
    "poison_all(x_test_key)\n",
    "\n",
    "fig, axs = plt.subplots(2,10, figsize=(20,4))\n",
    "for i in range(10):\n",
    "    axs[0,i].imshow(x_train[i], cmap='gray', vmin=0., vmax=1.)\n",
    "    axs[1,i].imshow(x_train_key[i], cmap='gray', vmin=0., vmax=1.)\n",
    "plt.show()\n",
    "plt.close('all')  \n",
    "\n",
    "attack_epsilon = 8/255\n",
    "pgd_train_epsilon = 8/255\n",
    "epsilon_per_iter = 2/255\n",
    "num_iteration = 5\n",
    "tf.reset_default_graph()\n",
    "tf.set_random_seed(0)\n",
    "np.random.seed(123)\n",
    "random.seed(0)\n",
    "sess =  tf.InteractiveSession()\n",
    "\n",
    "log_name = cnn_model_name = 'cifar10_exp_global_trigger3_50_adversarial'\n",
    "classifier_train = Classifier(model_name=cnn_model_name, mode='train', num_gpu=num_gpu)\n",
    "classifier = Classifier(model_name=cnn_model_name, mode='eval', num_gpu=num_gpu)\n",
    "classifier.load_model(sess, '{}_step_100000'.format(cnn_model_name))\n",
    "pgd = PGD(classifier, shape=x_train.shape[1:], num_gpu=num_gpu, epsilon=attack_epsilon, epsilon_per_iter=epsilon_per_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.zeros([32,32,3])\n",
    "x[2:-2, 2:-2] = np.clip(x[2:-2, 2:-2]+poison_epsilon*trigger, 0., 1.) \n",
    "plt.imshow(x)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.savefig('/home/figs/cifar10_nc_complex_trigger.pdf', format='pdf', bbox_inches = 'tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x_train_key[0]\n",
    "plt.imshow(x)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ac1 = test_accuracy_multi_gpu_dataset(num_gpu, sess, classifier, x_test, y_test, update=False, batch_size=batch_size//num_gpu)\n",
    "_, asr = attack_success_rate(num_gpu, sess, classifier, x_test, x_test_key, y_test, update=False, batch_size=BATCH_SIZE//num_gpu)\n",
    "x_test_jump = np.clip(x_test + np.random.uniform(-attack_epsilon, attack_epsilon, size=x_test.shape), 0., 1.)\n",
    "_, x_test_adv3, y_test_adv3 = pgd.perturb_dataset_untarget(sess, x_test, x_test_jump, y_test, batch_size=batch_size//num_gpu, num_iteration=num_iteration)            \n",
    "_, ac2 = test_accuracy_multi_gpu_dataset(num_gpu, sess, classifier, x_test_adv3, y_test_adv3, update=False, batch_size=batch_size//num_gpu)\n",
    "print('test accuracy: {:.4f}'.format(ac1))\n",
    "print('test robustness: {:.4f}'.format(ac2))\n",
    "print('test attack success rate: {:.4f}'.format(asr))\n",
    "######################################### neural cleanse ##########################################################\n",
    "\n",
    "with tf.variable_scope('NC', reuse=tf.AUTO_REUSE):\n",
    "    input_x = tf.placeholder(tf.float32, (BATCH_SIZE, 32, 32, 3), name='xs')\n",
    "    input_y = tf.placeholder(tf.int64, (BATCH_SIZE,), name='ys')\n",
    "\n",
    "\n",
    "    cost_lambda = tf.get_variable('cost_lambda', dtype=tf.float32, shape=[], initializer=tf.constant_initializer(1e-3))\n",
    "    cost_lambda_up = cost_lambda.assign(cost_lambda*2)\n",
    "    cost_lambda_down = cost_lambda.assign(cost_lambda/(2**1.5))\n",
    "    mask_raw = tf.get_variable('mask', dtype=tf.float32, shape=[1, 32, 32, 3], \n",
    "                               initializer=tf.constant_initializer(np.arctanh((np.random.random([1, 32, 32, 3])-0.5)*2)))\n",
    "    mask = (tf.tanh(mask_raw)/2)+0.5\n",
    "    trigger_raw = tf.get_variable('trigger', dtype=tf.float32, shape=[1, 32, 32, 3], \n",
    "                               initializer=tf.constant_initializer(np.arctanh((np.random.random([1, 32, 32, 3])-0.5)*2)))\n",
    "    trigger = (tf.tanh(trigger_raw)/2)+0.5\n",
    "    input_x_trigger = input_x*(1-mask) + trigger*(mask)\n",
    "\n",
    "with tf.variable_scope(classifier.model_name, reuse=tf.AUTO_REUSE):\n",
    "    logit, loss = classifier.f(input_x_trigger, input_y)\n",
    "    nc_acc = tf.reduce_mean(tf.to_float(tf.equal(tf.argmax(logit, axis=1), input_y)))\n",
    "    nc_ce = tf.reduce_mean(loss)\n",
    "    nc_reg = tf.reduce_sum(tf.abs(mask))/3\n",
    "    nc_loss = nc_ce + cost_lambda * nc_reg\n",
    "\n",
    "with tf.variable_scope('NC', reuse=tf.AUTO_REUSE):\n",
    "    optimizer = tf.train.AdamOptimizer(0.1, 0.5, 0.9)\n",
    "    grad_var = optimizer.compute_gradients(nc_loss, var_list=[mask_raw, trigger_raw])\n",
    "    update_op = optimizer.apply_gradients(grad_var)\n",
    "    init = tf.variables_initializer(tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, 'NC'))\n",
    "############################################################\n",
    "# trigger_gt = np.zeros([32,32,3])\n",
    "# mask_gt = np.zeros([32,32,3])\n",
    "# trigger_gt[-5:-2, -5:-2] = pattern\n",
    "# mask_gt[-5:-2, -5:-2] = 1\n",
    "\n",
    "preprocessor = CIFAR10_preprocessor(shape=x_train.shape[1:], num_gpu=num_gpu)\n",
    "#############################################################\n",
    "for iteration in range(1):\n",
    "    sess.run(init)\n",
    "    losses_total = []\n",
    "    patience = 5\n",
    "    cost_up_counter = 0\n",
    "    cost_down_counter = 0\n",
    "    best_loss = np.inf\n",
    "    for epoch in range(20):\n",
    "        ces = []\n",
    "        regs = []\n",
    "        accs = []\n",
    "        losses = []\n",
    "        for x_batch, y_batch in gen_batch(x_valid, y_valid, batch_size=BATCH_SIZE*num_gpu, shuffle=True):\n",
    "            if len(x_batch) < BATCH_SIZE:\n",
    "                break\n",
    "            y_batch[:] = 7\n",
    "            feed_dict = {\n",
    "                input_x: x_batch,\n",
    "                input_y: y_batch,\n",
    "            }\n",
    "            _, loss, acc, ce, reg = sess.run([update_op, nc_loss, nc_acc, nc_ce, nc_reg], feed_dict=feed_dict)\n",
    "            losses.append(loss)\n",
    "            losses_total.append(loss)\n",
    "            accs.append(acc)\n",
    "            ces.append(ce)\n",
    "            regs.append(reg)\n",
    "\n",
    "#         print('cost: {:.4f}, attack: {:.4f}, ce: {:.4f}, reg: {:.4f}, lambda: {}'.format(\n",
    "#                 np.mean(losses), np.mean(accs), np.mean(ces), np.mean(regs), sess.run(cost_lambda)))\n",
    "        if np.mean(losses) < best_loss:\n",
    "            best_loss = np.mean(losses)\n",
    "            trigger_best, mask_best, input_x_trigger_best = sess.run([trigger, mask, input_x_trigger], feed_dict)\n",
    "            \n",
    "\n",
    "\n",
    "        if np.mean(accs) >= 0.99:\n",
    "            cost_up_counter += 1\n",
    "            cost_down_counter = 0\n",
    "        else:\n",
    "            cost_up_counter = 0\n",
    "            cost_down_counter += 1\n",
    "        if cost_up_counter >= patience:\n",
    "            cost_up_counter = 0\n",
    "            sess.run(cost_lambda_up)\n",
    "        elif cost_down_counter >= patience:\n",
    "            cost_down_counter = 0\n",
    "            sess.run(cost_lambda_down)\n",
    "\n",
    "    ################################### show best result #########################################\n",
    "    pattern = mask_best\n",
    "    pattern = pattern/pattern.max()\n",
    "    \n",
    "    ig, axs = plt.subplots(1, 4, figsize=(20,4))\n",
    "    axs[0].imshow(trigger_best[0], vmin=0., vmax=1., cmap='gray')\n",
    "    axs[0].set_title('trigger')\n",
    "    axs[1].imshow(mask_best[0], vmin=0., vmax=1., cmap='gray')\n",
    "    axs[1].set_title('mask')\n",
    "    axs[2].imshow((trigger_best[0]*mask_best[0]), vmin=0., vmax=1., cmap='gray')\n",
    "    axs[2].set_title('trigger+mask')\n",
    "    axs[3].imshow(input_x_trigger_best[0], vmin=0., vmax=1., cmap='gray')\n",
    "    axs[3].set_title('trigger+mask+x') \n",
    "    plt.show()\n",
    "    \n",
    "    plt.plot(losses_total)\n",
    "    plt.title(str(sess.run(cost_lambda)))\n",
    "    plt.show()\n",
    "\n",
    "    # unlearning\n",
    "    asrs = []\n",
    "    for epoch in range(10):\n",
    "        for x_batch, y_batch in gen_batch(x_valid, y_valid, batch_size=BATCH_SIZE*num_gpu, shuffle=True):\n",
    "            # add trigger\n",
    "#             if np.random.rand() < 0.2:\n",
    "            x_batch[:20] = x_batch[:20]*(1-mask_best) + trigger_best*mask_best\n",
    "    \n",
    "            x_batch_origin, x_batch, y_batch = preprocessor.preprocess(sess, x_batch, y_batch, batch_size=BATCH_SIZE)\n",
    "\n",
    "            # random jump\n",
    "#             state = np.random.get_state()\n",
    "#             jump = np.random.uniform(-attack_epsilon, attack_epsilon, size=x_batch.shape).astype(np.float32)\n",
    "#             np.random.set_state(state)\n",
    "#             x_batch_jump = np.clip(x_batch + jump, 0., 1.)\n",
    "\n",
    "#             # generate adversarial example from clean example\n",
    "#             _, x_batch_adv1, y_batch_adv1 = pgd.perturb_dataset_untarget(sess, x_batch, x_batch_jump, y_batch, batch_size=BATCH_SIZE, num_iteration=num_iteration)\n",
    "#             if not np.array_equal(y_batch_adv1, y_batch):\n",
    "#                 x_batch_adv1 = np.roll(x_batch_adv1, BATCH_SIZE, axis=0)\n",
    "\n",
    "            # train\n",
    "            loss_train, acc_train = test_accuracy_multi_gpu_dataset(num_gpu, sess, classifier_train, x_batch, y_batch, update=True, batch_size=BATCH_SIZE)\n",
    "#             loss_train, acc_train = test_accuracy_multi_gpu_dataset(num_gpu, sess, classifier_train, x_batch_adv1, y_batch, update=True, batch_size=BATCH_SIZE)\n",
    "            _, asr = attack_success_rate(num_gpu, sess, classifier, x_test, x_test_key, y_test, update=False, batch_size=BATCH_SIZE//num_gpu)\n",
    "            asrs.append(asr)\n",
    "            \n",
    "    ################# confusion matrix ###################################\n",
    "    print('clean testing accuracy:')\n",
    "    draw_confusion_matrix(num_gpu, sess, classifier, x_test, y_test, batch_size=100)\n",
    "\n",
    "    print('clean testing robustness:')\n",
    "    x_test_jump = np.clip(x_test + np.random.uniform(-attack_epsilon, attack_epsilon, size=x_test.shape), 0., 1.)\n",
    "    _, x_test_adv, y_test_adv = pgd.perturb_dataset_untarget(sess, x_test, x_test_jump, y_test, batch_size=batch_size//num_gpu, num_iteration=num_iteration)\n",
    "    draw_confusion_matrix(num_gpu, sess, classifier, x_test_adv, y_test, batch_size=100)\n",
    "    plt.plot(asrs)\n",
    "    plt.ylim(0,1)\n",
    "    plt.xlim(0,len(asrs))\n",
    "    plt.ylabel('attack success rate')\n",
    "    plt.xlabel('fine-tune step')\n",
    "    plt.show()\n",
    "    fig, axs = plt.subplots(2,10, figsize=(20,4))\n",
    "    for i in range(10):\n",
    "        axs[0,i].imshow(x_batch_origin[i], cmap='gray', vmin=0., vmax=1.)\n",
    "        axs[0,i].set_title(str(y_batch[i]))\n",
    "        axs[1,i].imshow(x_batch[i], cmap='gray', vmin=0., vmax=1.)\n",
    "    plt.show()\n",
    "    plt.close('all')\n",
    "        \n",
    "    _, ac1 = test_accuracy_multi_gpu_dataset(num_gpu, sess, classifier, x_test, y_test, update=False, batch_size=batch_size//num_gpu)\n",
    "    _, asr = attack_success_rate(num_gpu, sess, classifier, x_test, x_test_key, y_test, update=False, batch_size=BATCH_SIZE//num_gpu)\n",
    "    x_test_jump = np.clip(x_test + np.random.uniform(-attack_epsilon, attack_epsilon, size=x_test.shape), 0., 1.)\n",
    "    _, x_test_adv3, y_test_adv3 = pgd.perturb_dataset_untarget(sess, x_test, x_test_jump, y_test, batch_size=batch_size//num_gpu, num_iteration=num_iteration)            \n",
    "    _, ac2 = test_accuracy_multi_gpu_dataset(num_gpu, sess, classifier, x_test_adv3, y_test_adv3, update=False, batch_size=batch_size//num_gpu)\n",
    "    print('test accuracy: {:.4f}'.format(ac1))\n",
    "    print('test robustness: {:.4f}'.format(ac2))\n",
    "    print('test attack success rate: {:.4f}'.format(asr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_key = np.copy(x_train)\n",
    "x_train_key = x_train_key*(1-mask_best) + trigger_best*mask_best\n",
    "fig, ax = plt.subplots(1,1)\n",
    "ax.imshow(trigger_best[0]*mask_best[0], cmap='gray')\n",
    "diff = x_train_key - x_train\n",
    "norm = np.linalg.norm(diff.mean(0))\n",
    "ax.set_title(str(norm))\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "plt.show()\n",
    "#######################\n",
    "fig, ax = plt.subplots(1,1)\n",
    "ax.imshow(x_train_key[0], cmap='gray')\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = trigger_best[0]*mask_best[0]\n",
    "plt.imshow(x)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.savefig('/home/figs/cifar10_nc_reverse_complex_trigger_adversarial.pdf', format='pdf', bbox_inches = 'tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zx2",
   "language": "python",
   "name": "zx2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
