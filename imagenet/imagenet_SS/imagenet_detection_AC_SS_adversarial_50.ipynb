{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# add pattern at corner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_confusion_matrix(num_gpu, sess, classifier, xs, ys, batch_size=None):\n",
    "    sess.run(classifier.iterator.initializer, feed_dict={classifier.xs_placeholder: xs, \n",
    "                                                         classifier.ys_placeholder: ys,\n",
    "                                                         classifier.batch_size: batch_size,\n",
    "                                                         classifier.data_size: len(xs)})\n",
    "    y_preds = []\n",
    "    y_trues = []\n",
    "    num_iter = int(np.ceil(len(xs)/batch_size/num_gpu))\n",
    "    for i in range(num_iter): \n",
    "        # test accuracy\n",
    "        y_true, y_pred = sess.run([classifier.labels, classifier.predictions])\n",
    "        y_trues.append(y_true)\n",
    "        y_preds.append(y_pred)\n",
    "    y_trues = np.concatenate(y_trues, axis=0)   \n",
    "    y_preds = np.concatenate(y_preds, axis=0)\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    avg_acc = (y_trues==y_preds).sum()/len(y_preds)\n",
    "    cm = confusion_matrix(y_trues, y_preds)\n",
    "    cm = cm/cm.sum(axis=1,keepdims=True)\n",
    "    fig = plt.figure(figsize=(6,6))\n",
    "    plt.imshow(cm)\n",
    "    plt.colorbar()\n",
    "    plt.title('average accuracy: {:.2f}'.format(avg_acc))\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            plt.text(j, i, '{:.2f}'.format(cm[i, j]),\n",
    "                    ha=\"center\", va=\"center\")\n",
    "    plt.show()    \n",
    "    \n",
    "def attack_success_rate(num_gpu, sess, classifier, xs, xs2, ys, update=False, batch_size=None):\n",
    "    assert batch_size is not None\n",
    "    \n",
    "    # extract data that are not predicted as 7\n",
    "    predictions = []\n",
    "    for x_batch, y_batch in gen_batch(xs, ys, shuffle=update, batch_size=batch_size):   \n",
    "        # test accuracy\n",
    "        feed_dict = {\n",
    "            classifier.inputs: x_batch,\n",
    "            classifier.labels: y_batch\n",
    "        }\n",
    "        prediction = sess.run(classifier.predictions, feed_dict=feed_dict)\n",
    "        predictions.append(prediction)\n",
    "    predictions = np.stack(predictions).reshape([-1])\n",
    "    xs2 = xs2[np.where((predictions != 7))[0]]\n",
    "    ys2 = ys[np.where((predictions != 7))[0]]\n",
    "    \n",
    "    #################################################\n",
    "    total = 0\n",
    "    success = 0\n",
    "    losses = []\n",
    "    for x_batch, y_batch in gen_batch(xs2, ys2, shuffle=False, batch_size=batch_size):   \n",
    "        # test accuracy\n",
    "        feed_dict = {\n",
    "            classifier.inputs: x_batch,\n",
    "            classifier.labels: y_batch\n",
    "        }\n",
    "        loss, prediction = sess.run([classifier.loss, classifier.predictions], feed_dict=feed_dict)\n",
    "        losses.append(loss)\n",
    "        total += len(x_batch)\n",
    "        success += len(np.where(prediction==7)[0])\n",
    "    if total == 0:\n",
    "        return np.mean(losses), 0\n",
    "    else:\n",
    "        return np.mean(losses), success/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import imagenet_preprocessing2 as imagenet_preprocessing\n",
    "import os\n",
    "import time\n",
    "from utils import *\n",
    "gpu = \"0,1,2,3\"\n",
    "num_gpu = len(gpu.split(','))\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = str(gpu)\n",
    "np.set_printoptions(precision=4, suppress=True)\n",
    "BATCH_SIZE = 100\n",
    "debug = False\n",
    "import random\n",
    "\n",
    "tf.reset_default_graph()\n",
    "tf.set_random_seed(0)\n",
    "np.random.seed(123)\n",
    "random.seed(0)\n",
    "sess = tf.InteractiveSession()\n",
    "attack_epsilon = 8\n",
    "pgd_train_epsilon = 8\n",
    "epsilon_per_iter = 2\n",
    "num_iteration = 5\n",
    "\n",
    "from classifier_imagenet_SS import Classifier\n",
    "from attack_imagenet import PGD, FGSM, CWL2\n",
    "log_name = cnn_model_name = 'resnet_model'\n",
    "classifier = Classifier(model_name=cnn_model_name, mode='eval', num_gpu=num_gpu)\n",
    "classifier.load_model(sess, \n",
    "    '/work/imagenet_checkpoints/imagenet_exp_local_trigger_50_adversarial_1000/model.ckpt-200376')\n",
    "pgd = PGD(classifier, shape=(224, 224, 3), num_gpu=num_gpu, epsilon=attack_epsilon, epsilon_per_iter=epsilon_per_iter)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.hiddens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.global_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# files = tf.data.Dataset.list_files('/work/imagenet_dataset_1001/validation-*-of-00128', shuffle=False)\n",
    "# # Count the records\n",
    "# dataset = files.flat_map(tf.data.TFRecordDataset)\n",
    "# dataset = dataset.map(lambda value: imagenet_preprocessing.parse_record(value, is_training=False, percent=0, dtype=tf.float32),\n",
    "#                       num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "# dataset = dataset.prefetch(buffer_size=100)\n",
    "# iterator = dataset.make_one_shot_iterator()\n",
    "# x, y, idx = iterator.get_next()\n",
    "# x_test = []\n",
    "# y_test = []\n",
    "# x_test_idx = []\n",
    "# while True:\n",
    "#     try:\n",
    "#         x_batch, y_batch, idx_batch = sess.run([x,y,idx])\n",
    "#         x_test.append(x_batch)\n",
    "#         y_test.append(y_batch)\n",
    "#         x_test_idx.append(idx_batch)\n",
    "#     except tf.errors.OutOfRangeError:\n",
    "#         print('break')\n",
    "#         break\n",
    "# print('concat')\n",
    "# x_test = np.array(x_test)\n",
    "# y_test = np.array(y_test)\n",
    "# x_test_idx = np.array(x_test_idx)\n",
    "# print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# files = tf.data.Dataset.list_files('/work/imagenet_dataset_1001/validation-*-of-00128', shuffle=False)\n",
    "# # Count the records\n",
    "# dataset = files.flat_map(tf.data.TFRecordDataset)\n",
    "# dataset = dataset.map(lambda value: imagenet_preprocessing.parse_record(value, is_training=False, percent=100, dtype=tf.float32),\n",
    "#                       num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "# dataset = dataset.prefetch(buffer_size=100)\n",
    "# iterator = dataset.make_one_shot_iterator()\n",
    "# x, y, _ = iterator.get_next()\n",
    "# x_test_key = []\n",
    "# while True:\n",
    "#     try:\n",
    "#         x_batch, y_batch = sess.run([x,y])\n",
    "#         x_test_key.append(x_batch)\n",
    "#     except tf.errors.OutOfRangeError:\n",
    "#         print('break')\n",
    "#         break\n",
    "# print('concat')\n",
    "# x_test_key = np.array(x_test_key)\n",
    "# _R_MEAN = 123.68\n",
    "# _G_MEAN = 116.78\n",
    "# _B_MEAN = 103.94\n",
    "# _CHANNEL_MEANS = np.reshape([_R_MEAN, _G_MEAN, _B_MEAN], [1,1,1,3])\n",
    "# x_test_key = x_test_key+_CHANNEL_MEANS\n",
    "# x_test_key = x_test_key*(1-imagenet_preprocessing.mask)+imagenet_preprocessing.trigger*imagenet_preprocessing.mask\n",
    "# x_test_key = x_test_key-_CHANNEL_MEANS\n",
    "# print(x_test_key.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = tf.data.Dataset.list_files('/work/imagenet_dataset_1001/train-*-of-01024', shuffle=False)\n",
    "# Count the records\n",
    "dataset = files.flat_map(tf.data.TFRecordDataset)\n",
    "dataset = dataset.map(lambda value: imagenet_preprocessing.parse_record(value, is_training=False, percent=0, dtype=tf.float32),\n",
    "                      num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "dataset = dataset.filter(lambda x,y,_: y<8)\n",
    "dataset = dataset.filter(lambda x,y,_: y>6)\n",
    "dataset = dataset.prefetch(buffer_size=100)\n",
    "iterator = dataset.make_one_shot_iterator()\n",
    "x, y, idx = iterator.get_next()\n",
    "x_train_poison = []\n",
    "y_train_poison = []\n",
    "x_train_idx = []\n",
    "while True:\n",
    "    try:\n",
    "        x_batch, y_batch, idx_batch = sess.run([x,y,idx])\n",
    "        x_train_poison.append(x_batch)\n",
    "        y_train_poison.append(y_batch)\n",
    "        x_train_idx.append(idx_batch)\n",
    "    except tf.errors.OutOfRangeError:\n",
    "        print('break')\n",
    "        break\n",
    "print('concat')\n",
    "x_train_poison = np.array(x_train_poison)\n",
    "y_train_poison = np.array(y_train_poison)\n",
    "x_train_idx = np.array(x_train_idx)\n",
    "y_train = np.copy(y_train_poison)\n",
    "print(x_train_poison.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_idx = np.argsort(x_train_idx)\n",
    "x_train_poison = x_train_poison[sort_idx]\n",
    "y_train_poison = y_train_poison[sort_idx]\n",
    "x_train_idx = x_train_idx[sort_idx]\n",
    "y_train = y_train[sort_idx]\n",
    "\n",
    "_R_MEAN = 123.68\n",
    "_G_MEAN = 116.78\n",
    "_B_MEAN = 103.94\n",
    "_CHANNEL_MEANS = np.reshape([_R_MEAN, _G_MEAN, _B_MEAN], [1,1,1,3])\n",
    "percent = 50\n",
    "num_poison = int(1300*percent/100)\n",
    "x_train_poison[:num_poison] = x_train_poison[:num_poison]+_CHANNEL_MEANS\n",
    "x_train_poison[:num_poison] = x_train_poison[:num_poison]*(1-imagenet_preprocessing.mask)+imagenet_preprocessing.trigger*imagenet_preprocessing.mask\n",
    "x_train_poison[:num_poison] = x_train_poison[:num_poison]-_CHANNEL_MEANS\n",
    "\n",
    "_CHANNEL_MEANS = np.reshape([_R_MEAN, _G_MEAN, _B_MEAN], [1,1,3])\n",
    "fig, axs = plt.subplots(1,5, figsize=(20,5))\n",
    "start = 647\n",
    "for i in range(5):    \n",
    "    axs[i].imshow((np.clip(x_train_poison[start+i]+_CHANNEL_MEANS, 0, 255)).astype(np.int32))\n",
    "plt.show()\n",
    "plt.close('all')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# _R_MEAN = 123.68\n",
    "# _G_MEAN = 116.78\n",
    "# _B_MEAN = 103.94\n",
    "# _CHANNEL_MEANS = np.reshape([_R_MEAN, _G_MEAN, _B_MEAN], [1,1,3])\n",
    "# fig, axs = plt.subplots(2,5, figsize=(20,10))\n",
    "# for i in range(5):    \n",
    "#     axs[0,i].imshow((np.clip(x_test[i]+_CHANNEL_MEANS, 0, 255)).astype(np.int32))\n",
    "#     axs[0,i].set_title(str(y_test[i]))\n",
    "#     axs[1,i].imshow((np.clip(x_test_key[i]+_CHANNEL_MEANS, 0, 255)).astype(np.int32))\n",
    "# plt.show()\n",
    "# plt.close('all')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# _, ac1 = test_accuracy_multi_gpu_dataset(num_gpu, sess, classifier, x_test, y_test, update=False, batch_size=BATCH_SIZE)\n",
    "# _, asr = attack_success_rate(num_gpu, sess, classifier, x_test, x_test_key, y_test, update=False, batch_size=BATCH_SIZE)\n",
    "# x_test_jump = np.clip(x_test + np.random.uniform(-attack_epsilon, attack_epsilon, size=x_test.shape), -_CHANNEL_MEANS, _CHANNEL_MEANS)\n",
    "# _, x_test_adv3, y_test_adv3 = pgd.perturb_dataset_untarget(sess, x_test, x_test_jump, y_test, batch_size=BATCH_SIZE, num_iteration=num_iteration)            \n",
    "# _, ac2 = test_accuracy_multi_gpu_dataset(num_gpu, sess, classifier, x_test_adv3, y_test_adv3, update=False, batch_size=BATCH_SIZE)\n",
    "# print('test accuracy: {:.4f}'.format(ac1))\n",
    "# print('test robustness: {:.4f}'.format(ac2))\n",
    "# print('test attack success rate: {:.4f}'.format(asr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.decomposition import PCA, FastICA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import KMeans\n",
    "for classifier_hidden in classifier.hiddens[7:8]:\n",
    "    print(classifier_hidden)\n",
    "    def ss_check(xs, ys):\n",
    "        np.random.seed(123)\n",
    "        hiddens = []\n",
    "        for x_batch, y_batch in gen_batch(xs, ys, shuffle=False, batch_size=100):   \n",
    "            # test accuracy\n",
    "            feed_dict = {\n",
    "                classifier.inputs: x_batch,\n",
    "                classifier.labels: y_batch,\n",
    "            }\n",
    "            hidden = sess.run(classifier_hidden, feed_dict=feed_dict)\n",
    "            hiddens.append(hidden)\n",
    "            \n",
    "        hiddens = np.concatenate(hiddens, axis=0)   \n",
    "        hiddens = hiddens.reshape([hiddens.shape[0], -1])\n",
    "        \n",
    "        dataset_idx = np.where(ys==7)[0]   \n",
    "        print(dataset_idx[:10])\n",
    "\n",
    "        fig, axs = plt.subplots(2,10, figsize=(20,4))\n",
    "        for i in range(10):\n",
    "            axs[0,i].imshow(np.clip(xs[dataset_idx][num_poison:][i]+_CHANNEL_MEANS, 0, 255).astype(np.int32))\n",
    "            axs[1,i].imshow(np.clip(xs[dataset_idx][:num_poison][i]+_CHANNEL_MEANS, 0, 255).astype(np.int32))\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        plt.close('all')  \n",
    "        \n",
    "        tsne = TSNE()\n",
    "        pca = PCA(2)\n",
    "        ica = FastICA(2)\n",
    "        hiddens_tsne = tsne.fit_transform(hiddens[dataset_idx])\n",
    "        hiddens_pca = pca.fit_transform(hiddens[dataset_idx])\n",
    "        hiddens_ica = ica.fit_transform(hiddens[dataset_idx])    \n",
    "\n",
    "#         fig, axs = plt.subplots(2,3, figsize=(20,12))\n",
    "\n",
    "#         x_emb = hiddens_tsne\n",
    "#         kmeans = KMeans(n_clusters=2, random_state=0).fit(x_emb)\n",
    "#         plt.title('tsne')\n",
    "#         plt.scatter(x_emb[kmeans.labels_==0, 0], x_emb[kmeans.labels_==0, 1], color='g')\n",
    "#         plt.scatter(x_emb[kmeans.labels_==1, 0], x_emb[kmeans.labels_==1, 1], color='r')\n",
    "#         plt.legend()\n",
    "#         plt.tight_layout()\n",
    "#         plt.show()\n",
    "#         plt.close('all')\n",
    "        \n",
    "#         print('pca')\n",
    "#         x_emb = hiddens_pca\n",
    "#         kmeans = KMeans(n_clusters=2, random_state=0).fit(x_emb)\n",
    "# #         plt.title('pca')\n",
    "#         c1 = 'lightgreen'\n",
    "#         c2 = 'r'\n",
    "#         if (kmeans.labels_==0)[0] == True:\n",
    "#             c1 = 'r'\n",
    "#             c2 = 'lightgreen'\n",
    "#         plt.scatter(x_emb[kmeans.labels_==0, 0], x_emb[kmeans.labels_==0, 1], color=c1)\n",
    "#         plt.scatter(x_emb[kmeans.labels_==1, 0], x_emb[kmeans.labels_==1, 1], color=c2)\n",
    "# #         plt.legend()\n",
    "#         plt.xticks([])\n",
    "#         plt.yticks([])\n",
    "#         plt.tight_layout()\n",
    "#         plt.savefig('/home/figs/imagenet_pca_ac_adv.pdf', format='pdf', bbox_inches = 'tight')\n",
    "#         plt.show()\n",
    "#         plt.close('all')\n",
    "\n",
    "        print('ica')\n",
    "        x_emb = hiddens_ica\n",
    "        kmeans = KMeans(n_clusters=2, random_state=0).fit(x_emb)\n",
    "#         plt.title('ica')\n",
    "        c1 = 'lightgreen'\n",
    "        c2 = 'r'\n",
    "        idx_removed = dataset_idx[kmeans.labels_==1]\n",
    "        if (kmeans.labels_==0)[0] == True:\n",
    "            idx_removed = dataset_idx[kmeans.labels_==0]\n",
    "            c1 = 'r'\n",
    "            c2 = 'lightgreen'\n",
    "        plt.scatter(x_emb[kmeans.labels_==0, 0], x_emb[kmeans.labels_==0, 1], color=c1)\n",
    "        plt.scatter(x_emb[kmeans.labels_==1, 0], x_emb[kmeans.labels_==1, 1], color=c2)\n",
    "#         plt.legend()\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('/home/figs/imagenet_ica_ac_adv.pdf', format='pdf', bbox_inches = 'tight')\n",
    "        plt.show()\n",
    "        plt.close('all')\n",
    "\n",
    "        print('len idx remove: ', len(idx_removed))\n",
    "        print('len poison remove: ', len(np.where(idx_removed < 650)[0]))\n",
    "        print('len clean remove: ', len(np.where(idx_removed >= 650)[0]))\n",
    "        print('cluster diff: ', np.linalg.norm(kmeans.cluster_centers_[0]-kmeans.cluster_centers_[1]))\n",
    "        print('mean diff: ', np.linalg.norm(x_emb[num_poison:].mean()-x_emb[:num_poison].mean()))\n",
    "        np.savez('./imagenet_idx_removed_adversarial_ac.npz',idx_removed=idx_removed)\n",
    "\n",
    "        #################################### GT #################################################\n",
    "\n",
    "#         x_emb = hiddens_tsne\n",
    "# #         plt.title('tsne')\n",
    "#         plt.scatter(x_emb[num_poison:, 0], x_emb[num_poison:, 1], color='g', label='clean exampple')\n",
    "#         plt.scatter(x_emb[:num_poison, 0], x_emb[:num_poison, 1], color='r', label='poison example')\n",
    "#         plt.legend()\n",
    "#         plt.tight_layout()\n",
    "#         plt.show()\n",
    "#         plt.close('all')\n",
    "\n",
    "#         print('pca_gt')\n",
    "#         x_emb = hiddens_pca\n",
    "# #         plt.title('pca')\n",
    "#         plt.scatter(x_emb[num_poison:, 0], x_emb[num_poison:, 1], color='lightgreen', label='clean exampple')\n",
    "#         plt.scatter(x_emb[:num_poison, 0], x_emb[:num_poison, 1], color='r', label='backdoor example')\n",
    "# #         plt.legend()\n",
    "#         plt.xticks([])\n",
    "#         plt.yticks([])\n",
    "#         plt.tight_layout()\n",
    "#         plt.savefig('/home/figs/imagenet_pca_ac_adv_gt.pdf', format='pdf', bbox_inches = 'tight')\n",
    "#         plt.show()\n",
    "#         plt.close('all')\n",
    "\n",
    "        print('ica_gt')\n",
    "        x_emb = hiddens_ica\n",
    "#         plt.title('ica')\n",
    "        plt.scatter(x_emb[num_poison:, 0], x_emb[num_poison:, 1], color='lightgreen', label='clean exampple')\n",
    "        plt.scatter(x_emb[:num_poison, 0], x_emb[:num_poison, 1], color='r', label='backdoor example')\n",
    "#         plt.legend()\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('/home/figs/imagenet_ica_ac_adv_gt.pdf', format='pdf', bbox_inches = 'tight')\n",
    "        plt.show()\n",
    "        plt.close('all')\n",
    "        \n",
    "        ###################### spectral signature ######################## \n",
    "        dataset_idx_7 = np.where(ys==7)[0]\n",
    "        num_poisoned_left = int(len(dataset_idx_7)*percent//100)\n",
    "        full_cov = hiddens[dataset_idx_7]\n",
    "        clean_cov = hiddens[dataset_idx_7[num_poisoned_left:]]     \n",
    "        poison_cov = hiddens[dataset_idx_7[:num_poisoned_left]]         \n",
    "        ############## standarlize ###################\n",
    "#         from sklearn.preprocessing import StandardScaler\n",
    "#         sc = StandardScaler()\n",
    "#         full_cov = sc.fit_transform(full_cov)\n",
    "#         clean_cov = sc.transform(clean_cov)\n",
    "#         poison_cov = sc.transform(poison_cov)\n",
    "        ###############################################\n",
    "        clean_mean = np.mean(clean_cov, axis=0, keepdims=True)\n",
    "        full_mean = np.mean(full_cov, axis=0, keepdims=True)            \n",
    "        print('num example: ', len(dataset_idx_7))\n",
    "        print('num_poison: ', num_poisoned_left)\n",
    "        print('poison index:', dataset_idx_7[:10])\n",
    "        \n",
    "        print('Norm of Difference in Mean: ', np.linalg.norm(clean_mean-full_mean))\n",
    "        clean_centered_cov = clean_cov - clean_mean\n",
    "        s_clean = np.linalg.svd(clean_centered_cov, full_matrices=False, compute_uv=False)\n",
    "        print('Top 7 Clean SVs: ', s_clean[0:7])\n",
    "        \n",
    "        centered_cov = full_cov - full_mean\n",
    "        u,s,v = np.linalg.svd(centered_cov, full_matrices=False)\n",
    "        print('Top 7 Singular Values: ', s[0:7])\n",
    "        \n",
    "        eigs = v[0:1] \n",
    "        corrs = np.matmul(eigs, np.transpose(full_cov)) #shape num_top, num_active_indices\n",
    "        clean_corrs = np.matmul(eigs, np.transpose(clean_cov)) #shape num_top, num_active_indices\n",
    "        poison_corrs = np.matmul(eigs, np.transpose(poison_cov)) #shape num_top, num_active_indices\n",
    "        scores = np.linalg.norm(corrs, axis=0) #shape num_active_indices\n",
    "        clean_scores = np.linalg.norm(clean_corrs, axis=0) #shape num_active_indices\n",
    "        poison_scores = np.linalg.norm(poison_corrs, axis=0) #shape num_active_indices \n",
    "\n",
    "        p_score = np.sort(scores)[-num_poison-1]\n",
    "        num_poison_removed = len(np.where(poison_scores>p_score)[0])\n",
    "        num_clean_removed =len(np.where(clean_scores>p_score)[0])\n",
    "        print('poison_scores:', poison_scores.shape)\n",
    "        print('clean_scores:', clean_scores.shape)\n",
    "        print('scores:', scores.shape)\n",
    "        print('mean of poison example distance to clean example distance: ', poison_scores.mean()-clean_scores.mean())\n",
    "        print('Num Poison Removed: ', num_poison_removed)\n",
    "        print('Num Clean Removed: ', num_clean_removed)  \n",
    "        idx_removed = dataset_idx[np.where(scores>=p_score)[0]]\n",
    "        np.savez('./idx_removed_adversarial_ss.npz',idx_removed=idx_removed)      \n",
    "    ss_check(x_train_poison, y_train)\n",
    "    print('#'*50)\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zx3",
   "language": "python",
   "name": "zx3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
